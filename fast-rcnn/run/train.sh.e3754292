Using Theano backend.
Using gpu device 0: Tesla K40c (CNMeM is disabled, cuDNN not available)
/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/engine/topology.py:368: UserWarning: The `regularizers` property of layers/models is deprecated. Regularization losses are now managed via the `losses` layer/model property.
  warnings.warn('The `regularizers` property of '
Traceback (most recent call last):
  File "tools/train_net.py", line 198, in <module>
    plt.plot(history.history['loss'])
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.py", line 3147, in plot
    ax = gca()
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.py", line 928, in gca
    return gcf().gca(**kwargs)
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.py", line 578, in gcf
    return figure()
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.py", line 527, in figure
    **kwargs)
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_qt4agg.py", line 46, in new_figure_manager
    return new_figure_manager_given_figure(num, thisFig)
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_qt4agg.py", line 53, in new_figure_manager_given_figure
    canvas = FigureCanvasQTAgg(figure)
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_qt4agg.py", line 76, in __init__
    FigureCanvasQT.__init__(self, figure)
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_qt4.py", line 68, in __init__
    _create_qApp()
  File "/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_qt5.py", line 138, in _create_qApp
    raise RuntimeError('Invalid DISPLAY variable')
RuntimeError: Invalid DISPLAY variable
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.059242e-04s
  Time in Function.fn.__call__: 4.770756e-04s (94.298%)
  Time in thunks: 4.680157e-04s (92.507%)
  Total compile time: 2.147410e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.617599e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.173091e-02s
       Import time 9.002209e-03s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.463s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.68e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.68e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.68e-04s      1     0   DeepCopyOp(convolution2d_1_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 1.909733e-04s
  Time in Function.fn.__call__: 1.659393e-04s (86.891%)
  Time in thunks: 1.578331e-04s (82.647%)
  Total compile time: 9.374189e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.433420e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.677202e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.466s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.58e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.58e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.58e-04s      1     0   DeepCopyOp(convolution2d_2_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 1.969337e-04s
  Time in Function.fn.__call__: 1.740456e-04s (88.378%)
  Time in thunks: 1.671314e-04s (84.867%)
  Total compile time: 8.858395e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.419783e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.701044e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.467s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.67e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.67e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.67e-04s      1     0   DeepCopyOp(convolution2d_3_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.198883e-04s
  Time in Function.fn.__call__: 5.948544e-04s (95.962%)
  Time in thunks: 5.869865e-04s (94.692%)
  Total compile time: 9.028292e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.408410e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.546072e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.469s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.87e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.87e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.87e-04s      1     0   DeepCopyOp(convolution2d_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.060600e-04s
  Time in Function.fn.__call__: 5.788803e-04s (95.515%)
  Time in thunks: 5.688667e-04s (93.863%)
  Total compile time: 9.209704e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.406503e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.779961e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.470s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.69e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.69e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.69e-04s      1     0   DeepCopyOp(convolution2d_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 6.041527e-04s
  Time in Function.fn.__call__: 5.671978e-04s (93.883%)
  Time in thunks: 5.559921e-04s (92.028%)
  Total compile time: 9.118199e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.462317e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.458811e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.471s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.56e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.56e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.56e-04s      1     0   DeepCopyOp(convolution2d_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.719662e-04s
  Time in Function.fn.__call__: 5.450249e-04s (95.290%)
  Time in thunks: 5.371571e-04s (93.914%)
  Total compile time: 9.280705e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.426911e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.759933e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.473s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.37e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.37e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.37e-04s      1     0   DeepCopyOp(convolution2d_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 5.350113e-04s
  Time in Function.fn.__call__: 5.068779e-04s (94.742%)
  Time in thunks: 4.990101e-04s (93.271%)
  Total compile time: 9.367108e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.419210e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.380941e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.474s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       4.99e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       4.99e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       4.99e-04s      1     0   DeepCopyOp(convolution2d_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.719994e-04s
  Time in Function.fn.__call__: 7.419586e-04s (96.109%)
  Time in thunks: 7.319450e-04s (94.812%)
  Total compile time: 1.027322e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.998019e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.828049e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.475s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       7.32e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       7.32e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       7.32e-04s      1     0   DeepCopyOp(convolution2d_9_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.789135e-04s
  Time in Function.fn.__call__: 7.510185e-04s (96.419%)
  Time in thunks: 7.190704e-04s (92.317%)
  Total compile time: 9.832191e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.447916e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.834082e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.477s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       7.19e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       7.19e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       7.19e-04s      1     0   DeepCopyOp(convolution2d_10_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.870197e-04s
  Time in Function.fn.__call__: 7.588863e-04s (96.425%)
  Time in thunks: 7.510185e-04s (95.426%)
  Total compile time: 9.749818e-02s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.435280e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.472971e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.478s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       7.51e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       7.51e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       7.51e-04s      1     0   DeepCopyOp(convolution2d_11_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.619858e-04s
  Time in Function.fn.__call__: 7.359982e-04s (96.589%)
  Time in thunks: 7.269382e-04s (95.401%)
  Total compile time: 1.070032e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.466799e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.554178e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.479s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       7.27e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       7.27e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       7.27e-04s      1     0   DeepCopyOp(convolution2d_12_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.600784e-04s
  Time in Function.fn.__call__: 7.321835e-04s (96.330%)
  Time in thunks: 7.231236e-04s (95.138%)
  Total compile time: 1.337330e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.517200e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.777100e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.480s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       7.23e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       7.23e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       7.23e-04s      1     0   DeepCopyOp(convolution2d_13_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.688999e-04s
  Time in Function.fn.__call__: 7.431507e-04s (96.651%)
  Time in thunks: 7.338524e-04s (95.442%)
  Total compile time: 1.256800e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.431203e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.720833e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.482s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       7.34e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       7.34e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       7.34e-04s      1     0   DeepCopyOp(convolution2d_14_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.629395e-04s
  Time in Function.fn.__call__: 7.359982e-04s (96.469%)
  Time in thunks: 7.259846e-04s (95.156%)
  Total compile time: 1.058211e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.503897e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.439976e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.483s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       7.26e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       7.26e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       7.26e-04s      1     0   DeepCopyOp(convolution2d_15_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 1 calls to Function.__call__: 7.259846e-04s
  Time in Function.fn.__call__: 6.990433e-04s (96.289%)
  Time in thunks: 6.899834e-04s (95.041%)
  Total compile time: 1.061862e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.432896e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.892971e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.484s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.90e-04s     C        1       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.90e-04s     C        1        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.90e-04s      1     0   DeepCopyOp(convolution2d_16_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 4.730225e-04s
  Time in Function.fn.__call__: 4.010201e-04s (84.778%)
  Time in thunks: 3.759861e-04s (79.486%)
  Total compile time: 4.711421e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.529908e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.262997e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.486s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.88e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.88e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.88e-04s      2     0   DeepCopyOp(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 3.759861e-04s
  Time in Function.fn.__call__: 3.111362e-04s (82.752%)
  Time in thunks: 2.958775e-04s (78.694%)
  Total compile time: 1.749098e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.486492e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.871990e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.487s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.000s       1.48e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.000s       1.48e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.000s       1.48e-04s      2     0   DeepCopyOp(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 9.369850e-04s
  Time in Function.fn.__call__: 8.742809e-04s (93.308%)
  Time in thunks: 8.540154e-04s (91.145%)
  Total compile time: 1.114430e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.445413e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.322840e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.488s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       4.27e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       4.27e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       4.27e-04s      2     0   DeepCopyOp(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.479149e-03s
  Time in Function.fn.__call__: 1.416206e-03s (95.745%)
  Time in thunks: 1.393080e-03s (94.181%)
  Total compile time: 1.117420e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.456404e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.059958e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.494s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.97e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.97e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.97e-04s      2     0   DeepCopyOp(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.183033e-03s
  Time in Function.fn.__call__: 1.116991e-03s (94.418%)
  Time in thunks: 1.096964e-03s (92.725%)
  Total compile time: 1.112759e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.456904e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.255129e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.495s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.48e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.48e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.48e-04s      2     0   DeepCopyOp(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.140118e-03s
  Time in Function.fn.__call__: 1.077890e-03s (94.542%)
  Time in thunks: 1.054049e-03s (92.451%)
  Total compile time: 1.088820e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.446199e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.209114e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.497s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.27e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.27e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.27e-04s      2     0   DeepCopyOp(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.159906e-03s
  Time in Function.fn.__call__: 1.105070e-03s (95.272%)
  Time in thunks: 1.081228e-03s (93.217%)
  Total compile time: 1.104870e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.447582e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.940987e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.498s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.41e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.41e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.41e-04s      2     0   DeepCopyOp(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.260996e-03s
  Time in Function.fn.__call__: 1.204967e-03s (95.557%)
  Time in thunks: 1.175880e-03s (93.250%)
  Total compile time: 1.083200e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.469612e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.204823e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.499s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.88e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.88e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.88e-04s      2     0   DeepCopyOp(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.267910e-03s
  Time in Function.fn.__call__: 1.205921e-03s (95.111%)
  Time in thunks: 1.187086e-03s (93.625%)
  Total compile time: 1.122990e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.453805e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.147125e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.500s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       5.94e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       5.94e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       5.94e-04s      2     0   DeepCopyOp(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.372099e-03s
  Time in Function.fn.__call__: 1.316071e-03s (95.917%)
  Time in thunks: 1.295805e-03s (94.440%)
  Total compile time: 1.122179e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.452589e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.878044e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.501s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.48e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.48e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.48e-04s      2     0   DeepCopyOp(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.304150e-03s
  Time in Function.fn.__call__: 1.248837e-03s (95.759%)
  Time in thunks: 1.229763e-03s (94.296%)
  Total compile time: 1.089010e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.482391e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.802134e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.503s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.15e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.15e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.15e-04s      2     0   DeepCopyOp(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.350880e-03s
  Time in Function.fn.__call__: 1.296997e-03s (96.011%)
  Time in thunks: 1.277924e-03s (94.599%)
  Total compile time: 1.103840e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.449108e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.275871e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.504s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.39e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.39e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.39e-04s      2     0   DeepCopyOp(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.332045e-03s
  Time in Function.fn.__call__: 1.266956e-03s (95.114%)
  Time in thunks: 1.245975e-03s (93.539%)
  Total compile time: 1.112351e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.445103e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.345013e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.505s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.23e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.23e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.23e-04s      2     0   DeepCopyOp(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.343966e-03s
  Time in Function.fn.__call__: 1.289129e-03s (95.920%)
  Time in thunks: 1.268864e-03s (94.412%)
  Total compile time: 1.117830e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.501203e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.843857e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.506s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.34e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.34e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.34e-04s      2     0   DeepCopyOp(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.292944e-03s
  Time in Function.fn.__call__: 1.237869e-03s (95.740%)
  Time in thunks: 1.219749e-03s (94.339%)
  Total compile time: 1.131411e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.457000e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.431082e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.507s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.10e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.10e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.10e-04s      2     0   DeepCopyOp(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1444
  Time in 2 calls to Function.__call__: 1.361132e-03s
  Time in Function.fn.__call__: 1.305103e-03s (95.884%)
  Time in thunks: 1.287937e-03s (94.623%)
  Total compile time: 1.125062e-01s
    Number of Apply nodes: 1
    Theano Optimizer time: 1.527405e-02s
       Theano validate time: 0.000000e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.846956e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.508s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%       0.001s       6.44e-04s     C        2       1   theano.compile.ops.DeepCopyOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%       0.001s       6.44e-04s     C        2        1   DeepCopyOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%       0.001s       6.44e-04s      2     0   DeepCopyOp(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 7.486343e-05s
  Time in Function.fn.__call__: 4.506111e-05s (60.191%)
  Time in thunks: 2.980232e-05s (39.809%)
  Total compile time: 2.398739e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.270985e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.305602e-02s
       Import time 2.356386e-02s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.510s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  90.4%    90.4%       0.000s       6.74e-06s     C        4       4   theano.compile.ops.Shape_i
   9.6%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  60.8%    60.8%       0.000s       1.81e-05s     C        1        1   Shape_i{0}
  13.6%    74.4%       0.000s       4.05e-06s     C        1        1   Shape_i{1}
   9.6%    84.0%       0.000s       2.86e-06s     C        1        1   Shape_i{2}
   9.6%    93.6%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
   6.4%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  60.8%    60.8%       0.000s       1.81e-05s      1     3   Shape_i{0}(convolution2d_17_W)
  13.6%    74.4%       0.000s       4.05e-06s      1     2   Shape_i{1}(convolution2d_17_W)
   9.6%    84.0%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   9.6%    93.6%       0.000s       2.86e-06s      1     1   Shape_i{2}(convolution2d_17_W)
   6.4%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 9.393692e-05s
  Time in Function.fn.__call__: 4.887581e-05s (52.030%)
  Time in thunks: 1.406670e-05s (14.975%)
  Total compile time: 1.102111e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.826501e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.168990e-02s
       Import time 8.116007e-03s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.514s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  78.0%    78.0%       0.000s       1.10e-05s     C        1       1   theano.compile.ops.Shape_i
  22.0%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  78.0%    78.0%       0.000s       1.10e-05s     C        1        1   Shape_i{0}
  22.0%   100.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  78.0%    78.0%       0.000s       1.10e-05s      1     0   Shape_i{0}(convolution2d_17_b)
  22.0%   100.0%       0.000s       3.10e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.793571e-05s
  Time in Function.fn.__call__: 3.790855e-05s (65.432%)
  Time in thunks: 2.408028e-05s (41.564%)
  Total compile time: 1.105189e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.286196e-02s
       Theano validate time: 3.314018e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.863926e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.515s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  79.2%    79.2%       0.000s       4.77e-06s     C        4       4   theano.compile.ops.Shape_i
  20.8%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  45.5%    45.5%       0.000s       1.10e-05s     C        1        1   Shape_i{0}
  20.8%    66.3%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  12.9%    79.2%       0.000s       3.10e-06s     C        1        1   Shape_i{1}
  11.9%    91.1%       0.000s       2.86e-06s     C        1        1   Shape_i{2}
   8.9%   100.0%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  45.5%    45.5%       0.000s       1.10e-05s      1     3   Shape_i{0}(convolution2d_18_W)
  20.8%    66.3%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.9%    79.2%       0.000s       3.10e-06s      1     2   Shape_i{1}(convolution2d_18_W)
  11.9%    91.1%       0.000s       2.86e-06s      1     1   Shape_i{2}(convolution2d_18_W)
   8.9%   100.0%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 2.694130e-05s (58.549%)
  Time in thunks: 1.382828e-05s (30.052%)
  Total compile time: 9.862089e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.823211e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.690958e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.518s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       1.00e-05s     C        1       1   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       3.81e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  72.4%    72.4%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  27.6%   100.0%       0.000s       3.81e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  72.4%    72.4%       0.000s       1.00e-05s      1     0   Shape_i{0}(convolution2d_18_b)
  27.6%   100.0%       0.000s       3.81e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.507469e-05s
  Time in Function.fn.__call__: 3.504753e-05s (63.636%)
  Time in thunks: 2.098083e-05s (38.095%)
  Total compile time: 1.102250e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.376699e-02s
       Theano validate time: 2.908707e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.339094e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.520s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.1%    76.1%       0.000s       3.99e-06s     C        4       4   theano.compile.ops.Shape_i
  23.9%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.2%    43.2%       0.000s       9.06e-06s     C        1        1   Shape_i{0}
  23.9%    67.0%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  14.8%    81.8%       0.000s       3.10e-06s     C        1        1   Shape_i{1}
  13.6%    95.5%       0.000s       2.86e-06s     C        1        1   Shape_i{2}
   4.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.2%    43.2%       0.000s       9.06e-06s      1     3   Shape_i{0}(convolution2d_19_W)
  23.9%    67.0%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  14.8%    81.8%       0.000s       3.10e-06s      1     2   Shape_i{1}(convolution2d_19_W)
  13.6%    95.5%       0.000s       2.86e-06s      1     1   Shape_i{2}(convolution2d_19_W)
   4.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.410744e-05s
  Time in Function.fn.__call__: 2.598763e-05s (58.919%)
  Time in thunks: 1.406670e-05s (31.892%)
  Total compile time: 9.796405e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.827598e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.541946e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.522s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  71.2%    71.2%       0.000s       1.00e-05s     C        1       1   theano.compile.ops.Shape_i
  28.8%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  71.2%    71.2%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  28.8%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  71.2%    71.2%       0.000s       1.00e-05s      1     0   Shape_i{0}(convolution2d_19_b)
  28.8%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.911423e-05s
  Time in Function.fn.__call__: 3.004074e-05s (61.165%)
  Time in thunks: 2.074242e-05s (42.233%)
  Total compile time: 1.106870e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.266622e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.138592e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.524s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  71.3%    71.3%       0.000s       3.70e-06s     C        4       4   theano.compile.ops.Shape_i
  28.7%   100.0%       0.000s       5.96e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  48.3%    48.3%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  28.7%    77.0%       0.000s       5.96e-06s     C        1        1   MakeVector{dtype='int64'}
   9.2%    86.2%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   9.2%    95.4%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   4.6%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  48.3%    48.3%       0.000s       1.00e-05s      1     3   Shape_i{0}(convolution2d_20_W)
  28.7%    77.0%       0.000s       5.96e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   9.2%    86.2%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_20_W)
   9.2%    95.4%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_20_W)
   4.6%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.577637e-05s
  Time in Function.fn.__call__: 2.503395e-05s (54.688%)
  Time in thunks: 1.287460e-05s (28.125%)
  Total compile time: 1.076190e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.820302e-02s
       Theano validate time: 2.813339e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.065111e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.526s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  77.8%    77.8%       0.000s       1.00e-05s     C        1       1   theano.compile.ops.Shape_i
  22.2%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  77.8%    77.8%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  22.2%   100.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  77.8%    77.8%       0.000s       1.00e-05s      1     0   Shape_i{0}(convolution2d_20_b)
  22.2%   100.0%       0.000s       2.86e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.698204e-05s
  Time in Function.fn.__call__: 3.600121e-05s (63.180%)
  Time in thunks: 2.121925e-05s (37.238%)
  Total compile time: 1.095259e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.282786e-02s
       Theano validate time: 2.884865e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.689880e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.528s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.4%    76.4%       0.000s       4.05e-06s     C        4       4   theano.compile.ops.Shape_i
  23.6%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.2%    47.2%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  23.6%    70.8%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  14.6%    85.4%       0.000s       3.10e-06s     C        1        1   Shape_i{1}
  10.1%    95.5%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
   4.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.2%    47.2%       0.000s       1.00e-05s      1     3   Shape_i{0}(convolution2d_21_W)
  23.6%    70.8%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  14.6%    85.4%       0.000s       3.10e-06s      1     2   Shape_i{1}(convolution2d_21_W)
  10.1%    95.5%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_21_W)
   4.5%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.506111e-05s
  Time in Function.fn.__call__: 2.598763e-05s (57.672%)
  Time in thunks: 1.502037e-05s (33.333%)
  Total compile time: 9.891701e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.832795e-02s
       Theano validate time: 2.717972e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.800154e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.531s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.0%    73.0%       0.000s       1.10e-05s     C        1       1   theano.compile.ops.Shape_i
  27.0%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  73.0%    73.0%       0.000s       1.10e-05s     C        1        1   Shape_i{0}
  27.0%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  73.0%    73.0%       0.000s       1.10e-05s      1     0   Shape_i{0}(convolution2d_21_b)
  27.0%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.507469e-05s
  Time in Function.fn.__call__: 3.600121e-05s (65.368%)
  Time in thunks: 2.217293e-05s (40.260%)
  Total compile time: 1.087191e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.276301e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.040833e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.532s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  77.4%    77.4%       0.000s       4.29e-06s     C        4       4   theano.compile.ops.Shape_i
  22.6%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  45.2%    45.2%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  22.6%    67.7%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  14.0%    81.7%       0.000s       3.10e-06s     C        1        1   Shape_i{1}
   9.7%    91.4%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
   8.6%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  45.2%    45.2%       0.000s       1.00e-05s      1     3   Shape_i{0}(convolution2d_22_W)
  22.6%    67.7%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  14.0%    81.7%       0.000s       3.10e-06s      1     2   Shape_i{1}(convolution2d_22_W)
   9.7%    91.4%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_22_W)
   8.6%   100.0%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.197525e-05s
  Time in Function.fn.__call__: 3.290176e-05s (63.303%)
  Time in thunks: 1.502037e-05s (28.899%)
  Total compile time: 1.012809e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 2.036500e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.658056e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.535s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       1.00e-05s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       1.00e-05s      1     0   Shape_i{0}(convolution2d_22_b)
  33.3%   100.0%       0.000s       5.01e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.602837e-05s
  Time in Function.fn.__call__: 3.695488e-05s (65.957%)
  Time in thunks: 2.121925e-05s (37.872%)
  Total compile time: 1.079390e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.281618e-02s
       Theano validate time: 2.598763e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.527994e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.536s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.4%    76.4%       0.000s       4.05e-06s     C        4       4   theano.compile.ops.Shape_i
  23.6%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.2%    47.2%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  23.6%    70.8%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  14.6%    85.4%       0.000s       3.10e-06s     C        1        1   Shape_i{1}
   9.0%    94.4%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   5.6%   100.0%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.2%    47.2%       0.000s       1.00e-05s      1     3   Shape_i{0}(convolution2d_23_W)
  23.6%    70.8%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  14.6%    85.4%       0.000s       3.10e-06s      1     2   Shape_i{1}(convolution2d_23_W)
   9.0%    94.4%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_23_W)
   5.6%   100.0%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 2.694130e-05s (58.549%)
  Time in thunks: 1.502037e-05s (32.642%)
  Total compile time: 9.995890e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.905608e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.783941e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.539s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.0%    73.0%       0.000s       1.10e-05s     C        1       1   theano.compile.ops.Shape_i
  27.0%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  73.0%    73.0%       0.000s       1.10e-05s     C        1        1   Shape_i{0}
  27.0%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  73.0%    73.0%       0.000s       1.10e-05s      1     0   Shape_i{0}(convolution2d_23_b)
  27.0%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.294250e-05s
  Time in Function.fn.__call__: 4.291534e-05s (68.182%)
  Time in thunks: 2.670288e-05s (42.424%)
  Total compile time: 1.272261e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.497816e-02s
       Theano validate time: 2.884865e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.276867e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.540s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  67.0%    67.0%       0.000s       4.47e-06s     C        4       4   theano.compile.ops.Shape_i
  33.0%   100.0%       0.000s       8.82e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  44.6%    44.6%       0.000s       1.19e-05s     C        1        1   Shape_i{0}
  33.0%    77.7%       0.000s       8.82e-06s     C        1        1   MakeVector{dtype='int64'}
  11.6%    89.3%       0.000s       3.10e-06s     C        1        1   Shape_i{1}
   7.1%    96.4%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   3.6%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  44.6%    44.6%       0.000s       1.19e-05s      1     3   Shape_i{0}(convolution2d_24_W)
  33.0%    77.7%       0.000s       8.82e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  11.6%    89.3%       0.000s       3.10e-06s      1     2   Shape_i{1}(convolution2d_24_W)
   7.1%    96.4%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_24_W)
   3.6%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 2.694130e-05s (57.360%)
  Time in thunks: 1.716614e-05s (36.548%)
  Total compile time: 9.830022e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.827312e-02s
       Theano validate time: 2.598763e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.624201e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.542s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.4%    76.4%       0.000s       1.31e-05s     C        1       1   theano.compile.ops.Shape_i
  23.6%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.4%    76.4%       0.000s       1.31e-05s     C        1        1   Shape_i{0}
  23.6%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.4%    76.4%       0.000s       1.31e-05s      1     0   Shape_i{0}(convolution2d_24_b)
  23.6%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.602837e-05s
  Time in Function.fn.__call__: 3.600121e-05s (64.255%)
  Time in thunks: 2.098083e-05s (37.447%)
  Total compile time: 1.087441e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.521801e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.617163e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.544s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.1%    76.1%       0.000s       3.99e-06s     C        4       4   theano.compile.ops.Shape_i
  23.9%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.7%    47.7%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  23.9%    71.6%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  10.2%    81.8%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
   9.1%    90.9%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   9.1%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.7%    47.7%       0.000s       1.00e-05s      1     3   Shape_i{0}(convolution2d_25_W)
  23.9%    71.6%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  10.2%    81.8%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_25_W)
   9.1%    90.9%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_25_W)
   9.1%   100.0%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.410744e-05s
  Time in Function.fn.__call__: 2.598763e-05s (58.919%)
  Time in thunks: 1.406670e-05s (31.892%)
  Total compile time: 9.943700e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.850986e-02s
       Theano validate time: 3.695488e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.622055e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.546s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  71.2%    71.2%       0.000s       1.00e-05s     C        1       1   theano.compile.ops.Shape_i
  28.8%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  71.2%    71.2%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  28.8%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  71.2%    71.2%       0.000s       1.00e-05s      1     0   Shape_i{0}(convolution2d_25_b)
  28.8%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.912781e-05s
  Time in Function.fn.__call__: 3.790855e-05s (64.113%)
  Time in thunks: 2.384186e-05s (40.323%)
  Total compile time: 1.090560e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.284598e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.517027e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.548s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  79.0%    79.0%       0.000s       4.71e-06s     C        4       4   theano.compile.ops.Shape_i
  21.0%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  50.0%    50.0%       0.000s       1.19e-05s     C        1        1   Shape_i{0}
  21.0%    71.0%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  12.0%    83.0%       0.000s       2.86e-06s     C        1        1   Shape_i{1}
   9.0%    92.0%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
   8.0%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  50.0%    50.0%       0.000s       1.19e-05s      1     3   Shape_i{0}(convolution2d_26_W)
  21.0%    71.0%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.0%    83.0%       0.000s       2.86e-06s      1     2   Shape_i{1}(convolution2d_26_W)
   9.0%    92.0%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_26_W)
   8.0%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 2.598763e-05s (56.477%)
  Time in thunks: 1.406670e-05s (30.570%)
  Total compile time: 9.849095e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.818609e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.673077e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.550s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  71.2%    71.2%       0.000s       1.00e-05s     C        1       1   theano.compile.ops.Shape_i
  28.8%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  71.2%    71.2%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  28.8%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  71.2%    71.2%       0.000s       1.00e-05s      1     0   Shape_i{0}(convolution2d_26_b)
  28.8%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.388260e-05s
  Time in Function.fn.__call__: 3.385544e-05s (62.832%)
  Time in thunks: 1.788139e-05s (33.186%)
  Total compile time: 1.083319e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.278090e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.387970e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.551s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  77.3%    77.3%       0.000s       3.46e-06s     C        4       4   theano.compile.ops.Shape_i
  22.7%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  49.3%    49.3%       0.000s       8.82e-06s     C        1        1   Shape_i{0}
  22.7%    72.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
  12.0%    84.0%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
  10.7%    94.7%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   5.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  49.3%    49.3%       0.000s       8.82e-06s      1     3   Shape_i{0}(convolution2d_27_W)
  22.7%    72.0%       0.000s       4.05e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.0%    84.0%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_27_W)
  10.7%    94.7%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_27_W)
   5.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.412102e-05s
  Time in Function.fn.__call__: 3.409386e-05s (62.996%)
  Time in thunks: 2.026558e-05s (37.445%)
  Total compile time: 1.025069e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.801705e-02s
       Theano validate time: 3.004074e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.122972e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.554s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  84.7%    84.7%       0.000s       1.72e-05s     C        1       1   theano.compile.ops.Shape_i
  15.3%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  84.7%    84.7%       0.000s       1.72e-05s     C        1        1   Shape_i{0}
  15.3%   100.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  84.7%    84.7%       0.000s       1.72e-05s      1     0   Shape_i{0}(convolution2d_27_b)
  15.3%   100.0%       0.000s       3.10e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.412102e-05s
  Time in Function.fn.__call__: 3.504753e-05s (64.758%)
  Time in thunks: 2.098083e-05s (38.767%)
  Total compile time: 1.087320e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.301097e-02s
       Theano validate time: 2.813339e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.989811e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.555s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.1%    76.1%       0.000s       3.99e-06s     C        4       4   theano.compile.ops.Shape_i
  23.9%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.7%    47.7%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  23.9%    71.6%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  14.8%    86.4%       0.000s       3.10e-06s     C        1        1   Shape_i{1}
   9.1%    95.5%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   4.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.7%    47.7%       0.000s       1.00e-05s      1     3   Shape_i{0}(convolution2d_28_W)
  23.9%    71.6%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  14.8%    86.4%       0.000s       3.10e-06s      1     2   Shape_i{1}(convolution2d_28_W)
   9.1%    95.5%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_28_W)
   4.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.720688e-05s
  Time in Function.fn.__call__: 2.694130e-05s (57.071%)
  Time in thunks: 1.502037e-05s (31.818%)
  Total compile time: 9.942198e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.834989e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.482819e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.557s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  74.6%    74.6%       0.000s       1.12e-05s     C        1       1   theano.compile.ops.Shape_i
  25.4%   100.0%       0.000s       3.81e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  74.6%    74.6%       0.000s       1.12e-05s     C        1        1   Shape_i{0}
  25.4%   100.0%       0.000s       3.81e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  74.6%    74.6%       0.000s       1.12e-05s      1     0   Shape_i{0}(convolution2d_28_b)
  25.4%   100.0%       0.000s       3.81e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.412102e-05s
  Time in Function.fn.__call__: 3.504753e-05s (64.758%)
  Time in thunks: 2.121925e-05s (39.207%)
  Total compile time: 1.078119e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.293396e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.870125e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.559s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.4%    76.4%       0.000s       4.05e-06s     C        4       4   theano.compile.ops.Shape_i
  23.6%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.2%    47.2%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  23.6%    70.8%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  10.1%    80.9%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  10.1%    91.0%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
   9.0%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.2%    47.2%       0.000s       1.00e-05s      1     3   Shape_i{0}(convolution2d_29_W)
  23.6%    70.8%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  10.1%    80.9%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_29_W)
  10.1%    91.0%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_29_W)
   9.0%   100.0%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 2.598763e-05s (56.477%)
  Time in thunks: 1.287460e-05s (27.979%)
  Total compile time: 9.833598e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.836300e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.498793e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.561s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  77.8%    77.8%       0.000s       1.00e-05s     C        1       1   theano.compile.ops.Shape_i
  22.2%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  77.8%    77.8%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  22.2%   100.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  77.8%    77.8%       0.000s       1.00e-05s      1     0   Shape_i{0}(convolution2d_29_b)
  22.2%   100.0%       0.000s       2.86e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.793571e-05s
  Time in Function.fn.__call__: 3.695488e-05s (63.786%)
  Time in thunks: 2.098083e-05s (36.214%)
  Total compile time: 4.311161e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 3.438110e-01s
       Theano validate time: 2.884865e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.747816e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.562s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.1%    76.1%       0.000s       3.99e-06s     C        4       4   theano.compile.ops.Shape_i
  23.9%   100.0%       0.000s       5.01e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.7%    47.7%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  23.9%    71.6%       0.000s       5.01e-06s     C        1        1   MakeVector{dtype='int64'}
  10.2%    81.8%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
   9.1%    90.9%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   9.1%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.7%    47.7%       0.000s       1.00e-05s      1     3   Shape_i{0}(convolution2d_30_W)
  23.9%    71.6%       0.000s       5.01e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  10.2%    81.8%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_30_W)
   9.1%    90.9%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_30_W)
   9.1%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.482269e-05s
  Time in Function.fn.__call__: 2.598763e-05s (57.979%)
  Time in thunks: 1.406670e-05s (31.383%)
  Total compile time: 9.818101e-02s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.829481e-02s
       Theano validate time: 4.196167e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.633022e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.564s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  71.2%    71.2%       0.000s       1.00e-05s     C        1       1   theano.compile.ops.Shape_i
  28.8%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  71.2%    71.2%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  28.8%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  71.2%    71.2%       0.000s       1.00e-05s      1     0   Shape_i{0}(convolution2d_30_b)
  28.8%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.698204e-05s
  Time in Function.fn.__call__: 3.600121e-05s (63.180%)
  Time in thunks: 2.169609e-05s (38.075%)
  Total compile time: 1.088171e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.322817e-02s
       Theano validate time: 3.385544e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 9.173155e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.566s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.5%    72.5%       0.000s       3.93e-06s     C        4       4   theano.compile.ops.Shape_i
  27.5%   100.0%       0.000s       5.96e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  45.1%    45.1%       0.000s       9.78e-06s     C        1        1   Shape_i{0}
  27.5%    72.5%       0.000s       5.96e-06s     C        1        1   MakeVector{dtype='int64'}
   9.9%    82.4%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
   8.8%    91.2%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   8.8%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  45.1%    45.1%       0.000s       9.78e-06s      1     3   Shape_i{0}(convolution2d_31_W)
  27.5%    72.5%       0.000s       5.96e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   9.9%    82.4%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_31_W)
   8.8%    91.2%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_31_W)
   8.8%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{3}(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.506111e-05s
  Time in Function.fn.__call__: 2.694130e-05s (59.788%)
  Time in thunks: 1.502037e-05s (33.333%)
  Total compile time: 1.001580e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 1.854014e-02s
       Theano validate time: 2.694130e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.765821e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.568s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.0%    73.0%       0.000s       1.10e-05s     C        1       1   theano.compile.ops.Shape_i
  27.0%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  73.0%    73.0%       0.000s       1.10e-05s     C        1        1   Shape_i{0}
  27.0%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  73.0%    73.0%       0.000s       1.10e-05s      1     0   Shape_i{0}(convolution2d_31_b)
  27.0%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.698204e-05s
  Time in Function.fn.__call__: 3.600121e-05s (63.180%)
  Time in thunks: 2.288818e-05s (40.167%)
  Total compile time: 1.114490e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 2.322412e-02s
       Theano validate time: 2.789497e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.183295e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.569s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  74.0%    74.0%       0.000s       4.23e-06s     C        4       4   theano.compile.ops.Shape_i
  26.0%   100.0%       0.000s       5.96e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  47.9%    47.9%       0.000s       1.10e-05s     C        1        1   Shape_i{0}
  26.0%    74.0%       0.000s       5.96e-06s     C        1        1   MakeVector{dtype='int64'}
  12.5%    86.5%       0.000s       2.86e-06s     C        1        1   Shape_i{1}
   9.4%    95.8%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
   4.2%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  47.9%    47.9%       0.000s       1.10e-05s      1     3   Shape_i{0}(convolution2d_32_W)
  26.0%    74.0%       0.000s       5.96e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  12.5%    86.5%       0.000s       2.86e-06s      1     2   Shape_i{1}(convolution2d_32_W)
   9.4%    95.8%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_32_W)
   4.2%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.197525e-05s
  Time in Function.fn.__call__: 2.193451e-05s (42.202%)
  Time in thunks: 1.001358e-05s (19.266%)
  Total compile time: 1.402740e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.619218e-02s
       Theano validate time: 5.578995e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.537987e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.571s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.5%    59.5%       0.000s       5.96e-06s     C        1       1   theano.compile.ops.Shape_i
  40.5%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.5%    59.5%       0.000s       5.96e-06s     C        1        1   Shape_i{0}
  40.5%   100.0%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.5%    59.5%       0.000s       5.96e-06s      1     0   Shape_i{0}(convolution2d_32_b)
  40.5%   100.0%       0.000s       4.05e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.792213e-05s
  Time in Function.fn.__call__: 1.811981e-05s (37.811%)
  Time in thunks: 7.867813e-06s (16.418%)
  Total compile time: 1.679919e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.937888e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.849413e-02s
       Import time 1.033902e-02s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.573s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.8%    75.8%       0.000s       2.98e-06s     C        2       2   theano.compile.ops.Shape_i
  24.2%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  39.4%    39.4%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  36.4%    75.8%       0.000s       2.86e-06s     C        1        1   Shape_i{1}
  24.2%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  39.4%    39.4%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_4_W)
  36.4%    75.8%       0.000s       2.86e-06s      1     0   Shape_i{1}(dense_4_W)
  24.2%   100.0%       0.000s       1.91e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.406670e-05s (35.119%)
  Time in thunks: 5.006790e-06s (12.500%)
  Total compile time: 1.507962e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.454781e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.186081e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.574s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_4_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.100800e-05s
  Time in Function.fn.__call__: 1.597404e-05s (38.953%)
  Time in thunks: 6.914139e-06s (16.860%)
  Total compile time: 1.450610e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 4.083586e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.235050e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.576s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       2.50e-06s     C        2       2   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  58.6%    58.6%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  27.6%    86.2%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  58.6%    58.6%       0.000s       4.05e-06s      1     1   Shape_i{0}(dense_5_W)
  27.6%    86.2%       0.000s       1.91e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  13.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.287460e-05s (32.143%)
  Time in thunks: 6.198883e-06s (15.476%)
  Total compile time: 1.425951e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.594494e-02s
       Theano validate time: 5.197525e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.498980e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.577s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  34.6%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  65.4%    65.4%       0.000s       4.05e-06s      1     0   Shape_i{0}(dense_5_b)
  34.6%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 1.716614e-05s (36.548%)
  Time in thunks: 7.152557e-06s (15.228%)
  Total compile time: 1.481578e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.525114e-02s
       Theano validate time: 4.792213e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.059025e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.579s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.0%    70.0%       0.000s       2.50e-06s     C        2       2   theano.compile.ops.Shape_i
  30.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.3%    43.3%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  30.0%    73.3%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  26.7%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.3%    43.3%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_6_W)
  30.0%    73.3%       0.000s       2.15e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  26.7%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{1}(dense_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.981590e-05s
  Time in Function.fn.__call__: 1.311302e-05s (32.934%)
  Time in thunks: 5.006790e-06s (12.575%)
  Total compile time: 1.523840e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.543997e-02s
       Theano validate time: 5.197525e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.192041e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.580s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_6_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.100800e-05s
  Time in Function.fn.__call__: 1.502037e-05s (36.628%)
  Time in thunks: 6.914139e-06s (16.860%)
  Total compile time: 1.559360e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.757811e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.359982e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.582s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       2.50e-06s     C        2       2   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  58.6%    58.6%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  27.6%    86.2%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  58.6%    58.6%       0.000s       4.05e-06s      1     1   Shape_i{0}(dense_7_W)
  27.6%    86.2%       0.000s       1.91e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  13.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.291534e-05s
  Time in Function.fn.__call__: 1.406670e-05s (32.778%)
  Time in thunks: 5.960464e-06s (13.889%)
  Total compile time: 1.544302e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.667593e-02s
       Theano validate time: 5.197525e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.502939e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.583s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(dense_7_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 1.692772e-05s (36.788%)
  Time in thunks: 7.152557e-06s (15.544%)
  Total compile time: 1.553731e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.741479e-02s
       Theano validate time: 4.792213e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.813931e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.585s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.3%    73.3%       0.000s       2.62e-06s     C        2       2   theano.compile.ops.Shape_i
  26.7%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.3%    43.3%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  30.0%    73.3%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  26.7%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  43.3%    43.3%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_8_W)
  30.0%    73.3%       0.000s       2.15e-06s      1     0   Shape_i{1}(dense_8_W)
  26.7%   100.0%       0.000s       1.91e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.287460e-05s (32.143%)
  Time in thunks: 5.006790e-06s (12.500%)
  Total compile time: 1.388311e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.440285e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.248070e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.587s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_8_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.196167e-05s
  Time in Function.fn.__call__: 1.597404e-05s (38.068%)
  Time in thunks: 5.960464e-06s (14.205%)
  Total compile time: 1.510510e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 4.001188e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.307053e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.588s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  84.0%    84.0%       0.000s       2.50e-06s     C        2       2   theano.compile.ops.Shape_i
  16.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  16.0%    84.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  16.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     1   Shape_i{0}(dense_9_W)
  16.0%    84.0%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  16.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_9_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.386902e-05s
  Time in Function.fn.__call__: 1.406670e-05s (32.065%)
  Time in thunks: 5.960464e-06s (13.587%)
  Total compile time: 1.503010e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.655887e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.495071e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.590s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(dense_9_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.698204e-05s
  Time in Function.fn.__call__: 2.598763e-05s (45.607%)
  Time in thunks: 1.478195e-05s (25.941%)
  Total compile time: 1.666241e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.486108e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.444793e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.591s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.6%    72.6%       0.000s       2.68e-06s     C        4       4   theano.compile.ops.Shape_i
  27.4%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  27.4%    27.4%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
  25.8%    53.2%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  19.4%    72.6%       0.000s       2.86e-06s     C        1        1   Shape_i{2}
  14.5%    87.1%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
  12.9%   100.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  27.4%    27.4%       0.000s       4.05e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  25.8%    53.2%       0.000s       3.81e-06s      1     3   Shape_i{0}(convolution2d_17_W)
  19.4%    72.6%       0.000s       2.86e-06s      1     1   Shape_i{2}(convolution2d_17_W)
  14.5%    87.1%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_17_W)
  12.9%   100.0%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_17_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.291534e-05s
  Time in Function.fn.__call__: 1.406670e-05s (32.778%)
  Time in thunks: 5.006790e-06s (11.667%)
  Total compile time: 1.510451e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.415012e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.746841e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.593s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  81.0%    81.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  81.0%    81.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_17_b)
  19.0%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.221367e-05s
  Time in Function.fn.__call__: 2.193451e-05s (42.009%)
  Time in thunks: 1.001358e-05s (19.178%)
  Total compile time: 1.691520e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.425693e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.381016e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.594s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  40.5%    40.5%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  21.4%    61.9%       0.000s       2.15e-06s     C        1        1   Shape_i{3}
  19.0%    81.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   9.5%    90.5%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   9.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  40.5%    40.5%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_18_W)
  21.4%    61.9%       0.000s       2.15e-06s      1     0   Shape_i{3}(convolution2d_18_W)
  19.0%    81.0%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   9.5%    90.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_18_W)
   9.5%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_18_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.410744e-05s
  Time in Function.fn.__call__: 1.478195e-05s (33.514%)
  Time in thunks: 5.245209e-06s (11.892%)
  Total compile time: 1.522310e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.660417e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.599094e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.597s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  40.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  40.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.1%    59.1%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_18_b)
  40.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 7.486343e-05s
  Time in Function.fn.__call__: 4.196167e-05s (56.051%)
  Time in thunks: 1.025200e-05s (13.694%)
  Total compile time: 1.666238e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.404211e-02s
       Theano validate time: 5.316734e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.362395e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.598s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  79.1%    79.1%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  20.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  30.2%    30.2%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  20.9%    51.2%       0.000s       2.15e-06s     C        1        1   Shape_i{2}
  20.9%    72.1%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  18.6%    90.7%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
   9.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  30.2%    30.2%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_19_W)
  20.9%    51.2%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  20.9%    72.1%       0.000s       2.15e-06s      1     1   Shape_i{2}(convolution2d_19_W)
  18.6%    90.7%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_19_W)
   9.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_19_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.600121e-05s
  Time in Function.fn.__call__: 1.192093e-05s (33.113%)
  Time in thunks: 5.006790e-06s (13.907%)
  Total compile time: 1.488421e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.412294e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.256964e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.600s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_19_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.292892e-05s
  Time in Function.fn.__call__: 2.193451e-05s (41.441%)
  Time in thunks: 9.298325e-06s (17.568%)
  Total compile time: 1.651380e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.504204e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.370215e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.601s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.9%    76.9%       0.000s       1.79e-06s     C        4       4   theano.compile.ops.Shape_i
  23.1%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.3%    33.3%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.1%    56.4%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  23.1%    79.5%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  10.3%    89.7%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  10.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.3%    33.3%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_20_W)
  23.1%    56.4%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  23.1%    79.5%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_20_W)
  10.3%    89.7%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_20_W)
  10.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_20_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.291534e-05s
  Time in Function.fn.__call__: 1.406670e-05s (32.778%)
  Time in thunks: 5.006790e-06s (11.667%)
  Total compile time: 1.527090e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.444719e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.835129e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.603s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_20_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.197525e-05s
  Time in Function.fn.__call__: 2.098083e-05s (40.367%)
  Time in thunks: 1.120567e-05s (21.560%)
  Total compile time: 1.661241e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.436803e-02s
       Theano validate time: 8.916855e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.411510e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.605s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.3%    72.3%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  27.7%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  27.7%    27.7%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  27.7%    55.3%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  19.1%    74.5%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  17.0%    91.5%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   8.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  27.7%    27.7%       0.000s       3.10e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  27.7%    55.3%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_21_W)
  19.1%    74.5%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_21_W)
  17.0%    91.5%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_21_W)
   8.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_21_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.315376e-05s
  Time in Function.fn.__call__: 1.406670e-05s (32.597%)
  Time in thunks: 4.768372e-06s (11.050%)
  Total compile time: 1.518130e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.670788e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.636049e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.606s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  60.0%    60.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  40.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  60.0%    60.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  40.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  60.0%    60.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_21_b)
  40.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.602837e-05s
  Time in Function.fn.__call__: 2.193451e-05s (39.149%)
  Time in thunks: 9.775162e-06s (17.447%)
  Total compile time: 1.657751e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.474688e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.712012e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.608s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.7%    70.7%       0.000s       1.73e-06s     C        4       4   theano.compile.ops.Shape_i
  29.3%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  29.3%    29.3%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  29.3%    58.5%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  19.5%    78.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  12.2%    90.2%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
   9.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  29.3%    29.3%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  29.3%    58.5%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_22_W)
  19.5%    78.0%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_22_W)
  12.2%    90.2%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_22_W)
   9.8%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_22_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.287460e-05s (32.143%)
  Time in thunks: 5.006790e-06s (12.500%)
  Total compile time: 1.422360e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.568196e-02s
       Theano validate time: 5.483627e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.662037e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.610s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_22_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.720688e-05s
  Time in Function.fn.__call__: 2.002716e-05s (42.424%)
  Time in thunks: 9.059906e-06s (19.192%)
  Total compile time: 1.659451e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.576802e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.259494e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.615s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.3%    76.3%       0.000s       1.73e-06s     C        4       4   theano.compile.ops.Shape_i
  23.7%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  42.1%    42.1%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  23.7%    65.8%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  13.2%    78.9%       0.000s       1.19e-06s     C        1        1   Shape_i{1}
  10.5%    89.5%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  10.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  42.1%    42.1%       0.000s       3.81e-06s      1     3   Shape_i{0}(convolution2d_23_W)
  23.7%    65.8%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.2%    78.9%       0.000s       1.19e-06s      1     2   Shape_i{1}(convolution2d_23_W)
  10.5%    89.5%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_23_W)
  10.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_23_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.504753e-05s
  Time in Function.fn.__call__: 1.192093e-05s (34.014%)
  Time in thunks: 5.006790e-06s (14.286%)
  Total compile time: 1.494169e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.604603e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.277945e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.617s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  42.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  57.1%    57.1%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  42.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  57.1%    57.1%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_23_b)
  42.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.982948e-05s
  Time in Function.fn.__call__: 2.098083e-05s (42.105%)
  Time in thunks: 8.821487e-06s (17.703%)
  Total compile time: 1.667929e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.609108e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.326895e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.618s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  78.4%    78.4%       0.000s       1.73e-06s     C        4       4   theano.compile.ops.Shape_i
  21.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  32.4%    32.4%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  21.6%    54.1%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  21.6%    75.7%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.5%    89.2%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
  10.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  32.4%    32.4%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_24_W)
  21.6%    54.1%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  21.6%    75.7%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_24_W)
  13.5%    89.2%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_24_W)
  10.8%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_24_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.386902e-05s
  Time in Function.fn.__call__: 1.382828e-05s (31.522%)
  Time in thunks: 6.198883e-06s (14.130%)
  Total compile time: 1.445260e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.684878e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.873991e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.620s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  34.6%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  65.4%    65.4%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  34.6%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  65.4%    65.4%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_24_b)
  34.6%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.078316e-05s
  Time in Function.fn.__call__: 2.503395e-05s (49.296%)
  Time in thunks: 1.406670e-05s (27.700%)
  Total compile time: 1.722851e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.607701e-02s
       Theano validate time: 5.912781e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.298213e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.621s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  71.2%    71.2%       0.000s       2.50e-06s     C        4       4   theano.compile.ops.Shape_i
  28.8%   100.0%       0.000s       4.05e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  28.8%    28.8%       0.000s       4.05e-06s     C        1        1   MakeVector{dtype='int64'}
  28.8%    57.6%       0.000s       4.05e-06s     C        1        1   Shape_i{3}
  20.3%    78.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  15.3%    93.2%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
   6.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  28.8%    28.8%       0.000s       4.05e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  28.8%    57.6%       0.000s       4.05e-06s      1     0   Shape_i{3}(convolution2d_25_W)
  20.3%    78.0%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_25_W)
  15.3%    93.2%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_25_W)
   6.8%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_25_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.886223e-05s
  Time in Function.fn.__call__: 1.311302e-05s (33.742%)
  Time in thunks: 4.768372e-06s (12.270%)
  Total compile time: 1.510320e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.644109e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.616022e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.623s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  60.0%    60.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  40.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  60.0%    60.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  40.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  60.0%    60.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_25_b)
  40.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 2.217293e-05s (47.208%)
  Time in thunks: 1.072884e-05s (22.843%)
  Total compile time: 1.593981e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.440904e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.254988e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.624s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  91.1%    91.1%       0.000s       2.44e-06s     C        4       4   theano.compile.ops.Shape_i
   8.9%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  64.4%    64.4%       0.000s       6.91e-06s     C        1        1   Shape_i{0}
   8.9%    73.3%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   8.9%    82.2%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   8.9%    91.1%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   8.9%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  64.4%    64.4%       0.000s       6.91e-06s      1     3   Shape_i{0}(convolution2d_26_W)
   8.9%    73.3%       0.000s       9.54e-07s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
   8.9%    82.2%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_26_W)
   8.9%    91.1%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_26_W)
   8.9%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_26_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.600121e-05s
  Time in Function.fn.__call__: 1.192093e-05s (33.113%)
  Time in thunks: 4.053116e-06s (11.258%)
  Total compile time: 1.423972e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.564596e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.323006e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.626s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  23.5%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.5%    76.5%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  23.5%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.5%    76.5%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_26_b)
  23.5%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.102158e-05s
  Time in Function.fn.__call__: 2.098083e-05s (41.121%)
  Time in thunks: 1.096725e-05s (21.495%)
  Total compile time: 1.654232e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.441500e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.375198e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.627s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.9%    73.9%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  26.1%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  37.0%    37.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  26.1%    63.0%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  17.4%    80.4%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  10.9%    91.3%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
   8.7%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  37.0%    37.0%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_27_W)
  26.1%    63.0%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  17.4%    80.4%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_27_W)
  10.9%    91.3%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_27_W)
   8.7%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_27_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.910065e-05s
  Time in Function.fn.__call__: 1.311302e-05s (33.537%)
  Time in thunks: 5.006790e-06s (12.805%)
  Total compile time: 1.514370e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.569698e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.605055e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.629s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_27_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 2.002716e-05s (43.523%)
  Time in thunks: 8.821487e-06s (19.171%)
  Total compile time: 1.570680e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.421496e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.284099e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.630s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  64.9%    64.9%       0.000s       1.43e-06s     C        4       4   theano.compile.ops.Shape_i
  35.1%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  35.1%    35.1%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  32.4%    67.6%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  10.8%    78.4%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  10.8%    89.2%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
  10.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  35.1%    35.1%       0.000s       3.10e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  32.4%    67.6%       0.000s       2.86e-06s      1     3   Shape_i{0}(convolution2d_28_W)
  10.8%    78.4%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_28_W)
  10.8%    89.2%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_28_W)
  10.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_28_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.410744e-05s
  Time in Function.fn.__call__: 1.382828e-05s (31.351%)
  Time in thunks: 5.245209e-06s (11.892%)
  Total compile time: 1.421399e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.571105e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.853010e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.632s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  40.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  59.1%    59.1%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  40.9%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  59.1%    59.1%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_28_b)
  40.9%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.197525e-05s
  Time in Function.fn.__call__: 2.098083e-05s (40.367%)
  Time in thunks: 9.059906e-06s (17.431%)
  Total compile time: 1.594732e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.376197e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.441407e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.633s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  78.9%    78.9%       0.000s       1.79e-06s     C        4       4   theano.compile.ops.Shape_i
  21.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  44.7%    44.7%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  21.1%    65.8%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.2%    78.9%       0.000s       1.19e-06s     C        1        1   Shape_i{2}
  10.5%    89.5%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  10.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  44.7%    44.7%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_29_W)
  21.1%    65.8%       0.000s       1.91e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  13.2%    78.9%       0.000s       1.19e-06s      1     1   Shape_i{2}(convolution2d_29_W)
  10.5%    89.5%       0.000s       9.54e-07s      1     2   Shape_i{1}(convolution2d_29_W)
  10.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_29_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.291534e-05s
  Time in Function.fn.__call__: 1.502037e-05s (35.000%)
  Time in thunks: 5.960464e-06s (13.889%)
  Total compile time: 1.524949e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.582907e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.896091e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.635s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(convolution2d_29_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.102158e-05s
  Time in Function.fn.__call__: 2.193451e-05s (42.991%)
  Time in thunks: 1.025200e-05s (20.093%)
  Total compile time: 1.972339e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.394197e-02s
       Theano validate time: 5.197525e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.750419e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.636s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  79.1%    79.1%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  20.9%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  30.2%    30.2%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  20.9%    51.2%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
  20.9%    72.1%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
  18.6%    90.7%       0.000s       1.91e-06s     C        1        1   Shape_i{2}
   9.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  30.2%    30.2%       0.000s       3.10e-06s      1     3   Shape_i{0}(convolution2d_30_W)
  20.9%    51.2%       0.000s       2.15e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  20.9%    72.1%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_30_W)
  18.6%    90.7%       0.000s       1.91e-06s      1     1   Shape_i{2}(convolution2d_30_W)
   9.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_30_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.817413e-05s
  Time in Function.fn.__call__: 2.694130e-05s (46.311%)
  Time in thunks: 1.788139e-05s (30.738%)
  Total compile time: 2.188821e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.550386e-02s
       Theano validate time: 5.316734e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.766104e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.638s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  89.3%    89.3%       0.000s       1.60e-05s     C        1       1   theano.compile.ops.Shape_i
  10.7%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  89.3%    89.3%       0.000s       1.60e-05s     C        1        1   Shape_i{0}
  10.7%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  89.3%    89.3%       0.000s       1.60e-05s      1     0   Shape_i{0}(convolution2d_30_b)
  10.7%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.102158e-05s
  Time in Function.fn.__call__: 2.098083e-05s (41.121%)
  Time in thunks: 1.072884e-05s (21.028%)
  Total compile time: 5.206130e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.385495e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 3.681278e-01s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.639s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  73.3%    73.3%       0.000s       1.97e-06s     C        4       4   theano.compile.ops.Shape_i
  26.7%   100.0%       0.000s       2.86e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  35.6%    35.6%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  26.7%    62.2%       0.000s       2.86e-06s     C        1        1   MakeVector{dtype='int64'}
  17.8%    80.0%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  11.1%    91.1%       0.000s       1.19e-06s     C        1        1   Shape_i{3}
   8.9%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  35.6%    35.6%       0.000s       3.81e-06s      1     3   Shape_i{0}(convolution2d_31_W)
  26.7%    62.2%       0.000s       2.86e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  17.8%    80.0%       0.000s       1.91e-06s      1     2   Shape_i{1}(convolution2d_31_W)
  11.1%    91.1%       0.000s       1.19e-06s      1     0   Shape_i{3}(convolution2d_31_W)
   8.9%   100.0%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_31_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.386902e-05s
  Time in Function.fn.__call__: 1.406670e-05s (32.065%)
  Time in thunks: 5.006790e-06s (11.413%)
  Total compile time: 1.639938e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.702402e-02s
       Theano validate time: 5.507469e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.250792e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.641s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(convolution2d_31_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.197525e-05s
  Time in Function.fn.__call__: 2.193451e-05s (42.202%)
  Time in thunks: 1.120567e-05s (21.560%)
  Total compile time: 2.059050e-01s
    Number of Apply nodes: 5
    Theano Optimizer time: 4.538012e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.015993e-02s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.642s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.3%    72.3%       0.000s       2.03e-06s     C        4       4   theano.compile.ops.Shape_i
  27.7%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  36.2%    36.2%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  27.7%    63.8%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
  19.1%    83.0%       0.000s       2.15e-06s     C        1        1   Shape_i{1}
   8.5%    91.5%       0.000s       9.54e-07s     C        1        1   Shape_i{2}
   8.5%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{3}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  36.2%    36.2%       0.000s       4.05e-06s      1     3   Shape_i{0}(convolution2d_32_W)
  27.7%    63.8%       0.000s       3.10e-06s      1     4   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{3}.0)
  19.1%    83.0%       0.000s       2.15e-06s      1     2   Shape_i{1}(convolution2d_32_W)
   8.5%    91.5%       0.000s       9.54e-07s      1     1   Shape_i{2}(convolution2d_32_W)
   8.5%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{3}(convolution2d_32_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.005432e-05s
  Time in Function.fn.__call__: 1.287460e-05s (32.143%)
  Time in thunks: 4.053116e-06s (10.119%)
  Total compile time: 1.469169e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.559017e-02s
       Theano validate time: 5.316734e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 5.259991e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.644s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  70.6%    70.6%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  29.4%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  70.6%    70.6%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  29.4%   100.0%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  70.6%    70.6%       0.000s       2.86e-06s      1     0   Shape_i{0}(convolution2d_32_b)
  29.4%   100.0%       0.000s       1.19e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.911423e-05s
  Time in Function.fn.__call__: 2.193451e-05s (44.660%)
  Time in thunks: 1.168251e-05s (23.786%)
  Total compile time: 1.512301e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.897095e-02s
       Theano validate time: 5.316734e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.343054e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.645s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  67.3%    67.3%       0.000s       7.87e-06s     C        1       1   theano.tensor.opt.MakeVector
  32.7%   100.0%       0.000s       1.91e-06s     C        2       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  67.3%    67.3%       0.000s       7.87e-06s     C        1        1   MakeVector{dtype='int64'}
  24.5%    91.8%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
   8.2%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  67.3%    67.3%       0.000s       7.87e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  24.5%    91.8%       0.000s       2.86e-06s      1     1   Shape_i{0}(dense_4_W)
   8.2%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_4_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 2.312660e-05s (49.239%)
  Time in thunks: 3.814697e-06s (8.122%)
  Total compile time: 1.441808e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.434610e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.302979e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.646s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  75.0%    75.0%       0.000s       2.86e-06s     C        1       1   theano.compile.ops.Shape_i
  25.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  75.0%    75.0%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  25.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  75.0%    75.0%       0.000s       2.86e-06s      1     0   Shape_i{0}(dense_4_b)
  25.0%   100.0%       0.000s       9.54e-07s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.194809e-05s
  Time in Function.fn.__call__: 1.192093e-05s (37.313%)
  Time in thunks: 5.006790e-06s (15.672%)
  Total compile time: 2.171848e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.799605e-02s
       Theano validate time: 5.412102e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.057978e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.647s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       2.03e-06s     C        2       2   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  19.0%    81.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_5_W)
  19.0%    81.0%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  19.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_5_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.696846e-05s
  Time in Function.fn.__call__: 1.597404e-05s (34.010%)
  Time in thunks: 5.722046e-06s (12.183%)
  Total compile time: 1.507239e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.518105e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.338026e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.649s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  66.7%    66.7%       0.000s       3.81e-06s     C        1       1   theano.compile.ops.Shape_i
  33.3%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  66.7%    66.7%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  33.3%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  66.7%    66.7%       0.000s       3.81e-06s      1     0   Shape_i{0}(dense_5_b)
  33.3%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.409386e-05s
  Time in Function.fn.__call__: 1.406670e-05s (41.259%)
  Time in thunks: 5.006790e-06s (14.685%)
  Total compile time: 1.556671e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.944206e-02s
       Theano validate time: 5.316734e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.812096e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.650s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  81.0%    81.0%       0.000s       2.03e-06s     C        2       2   theano.compile.ops.Shape_i
  19.0%   100.0%       0.000s       9.54e-07s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  19.0%    81.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
  19.0%   100.0%       0.000s       9.54e-07s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     1   Shape_i{0}(dense_6_W)
  19.0%    81.0%       0.000s       9.54e-07s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  19.0%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_6_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.194809e-05s
  Time in Function.fn.__call__: 1.001358e-05s (31.343%)
  Time in thunks: 5.006790e-06s (15.672%)
  Total compile time: 1.416719e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.510594e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.007101e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.651s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1       1   theano.compile.ops.Shape_i
  38.1%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  61.9%    61.9%       0.000s       3.10e-06s     C        1        1   Shape_i{0}
  38.1%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  61.9%    61.9%       0.000s       3.10e-06s      1     0   Shape_i{0}(dense_6_b)
  38.1%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.506111e-05s
  Time in Function.fn.__call__: 1.883507e-05s (41.799%)
  Time in thunks: 1.025200e-05s (22.751%)
  Total compile time: 1.520820e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 4.006505e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.659985e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.652s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  88.4%    88.4%       0.000s       4.53e-06s     C        2       2   theano.compile.ops.Shape_i
  11.6%   100.0%       0.000s       1.19e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  79.1%    79.1%       0.000s       8.11e-06s     C        1        1   Shape_i{0}
  11.6%    90.7%       0.000s       1.19e-06s     C        1        1   MakeVector{dtype='int64'}
   9.3%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  79.1%    79.1%       0.000s       8.11e-06s      1     1   Shape_i{0}(dense_7_W)
  11.6%    90.7%       0.000s       1.19e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
   9.3%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_7_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 3.886223e-05s
  Time in Function.fn.__call__: 1.311302e-05s (33.742%)
  Time in thunks: 5.960464e-06s (15.337%)
  Total compile time: 1.440170e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.568292e-02s
       Theano validate time: 5.221367e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.498005e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.653s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  64.0%    64.0%       0.000s       3.81e-06s     C        1       1   theano.compile.ops.Shape_i
  36.0%   100.0%       0.000s       2.15e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  64.0%    64.0%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
  36.0%   100.0%       0.000s       2.15e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  64.0%    64.0%       0.000s       3.81e-06s      1     0   Shape_i{0}(dense_7_b)
  36.0%   100.0%       0.000s       2.15e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.601479e-05s
  Time in Function.fn.__call__: 1.692772e-05s (36.788%)
  Time in thunks: 6.675720e-06s (14.508%)
  Total compile time: 1.524580e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.780603e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 8.103848e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.655s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  71.4%    71.4%       0.000s       2.38e-06s     C        2       2   theano.compile.ops.Shape_i
  28.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  42.9%    42.9%       0.000s       2.86e-06s     C        1        1   Shape_i{0}
  28.6%    71.4%       0.000s       1.91e-06s     C        1        1   Shape_i{1}
  28.6%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  42.9%    42.9%       0.000s       2.86e-06s      1     1   Shape_i{0}(dense_8_W)
  28.6%    71.4%       0.000s       1.91e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  28.6%   100.0%       0.000s       1.91e-06s      1     0   Shape_i{1}(dense_8_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 5.006790e-05s
  Time in Function.fn.__call__: 2.002716e-05s (40.000%)
  Time in thunks: 1.311302e-05s (26.190%)
  Total compile time: 1.415169e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.286290e-02s
       Theano validate time: 5.197525e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.873991e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.656s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  76.4%    76.4%       0.000s       1.00e-05s     C        1       1   theano.compile.ops.Shape_i
  23.6%   100.0%       0.000s       3.10e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  76.4%    76.4%       0.000s       1.00e-05s     C        1        1   Shape_i{0}
  23.6%   100.0%       0.000s       3.10e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  76.4%    76.4%       0.000s       1.00e-05s      1     0   Shape_i{0}(dense_8_b)
  23.6%   100.0%       0.000s       3.10e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 6.198883e-05s
  Time in Function.fn.__call__: 1.597404e-05s (25.769%)
  Time in thunks: 6.914139e-06s (11.154%)
  Total compile time: 1.536450e-01s
    Number of Apply nodes: 3
    Theano Optimizer time: 3.834105e-02s
       Theano validate time: 5.292892e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 7.901192e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.657s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  72.4%    72.4%       0.000s       2.50e-06s     C        2       2   theano.compile.ops.Shape_i
  27.6%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  58.6%    58.6%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  27.6%    86.2%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
  13.8%   100.0%       0.000s       9.54e-07s     C        1        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  58.6%    58.6%       0.000s       4.05e-06s      1     1   Shape_i{0}(dense_9_W)
  27.6%    86.2%       0.000s       1.91e-06s      1     2   MakeVector{dtype='int64'}(Shape_i{0}.0, Shape_i{1}.0)
  13.8%   100.0%       0.000s       9.54e-07s      1     0   Shape_i{1}(dense_9_W)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:192
  Time in 1 calls to Function.__call__: 4.291534e-05s
  Time in Function.fn.__call__: 1.406670e-05s (32.778%)
  Time in thunks: 5.960464e-06s (13.889%)
  Total compile time: 1.496420e-01s
    Number of Apply nodes: 2
    Theano Optimizer time: 3.555989e-02s
       Theano validate time: 5.388260e-05s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.925966e-03s
       Import time 0.000000e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.658s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1       1   theano.compile.ops.Shape_i
  32.0%   100.0%       0.000s       1.91e-06s     C        1       1   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.0%    68.0%       0.000s       4.05e-06s     C        1        1   Shape_i{0}
  32.0%   100.0%       0.000s       1.91e-06s     C        1        1   MakeVector{dtype='int64'}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.0%    68.0%       0.000s       4.05e-06s      1     0   Shape_i{0}(dense_9_b)
  32.0%   100.0%       0.000s       1.91e-06s      1     1   MakeVector{dtype='int64'}(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:915
  Time in 150000 calls to Function.__call__: 9.889766e+05s
  Time in Function.fn.__call__: 9.888098e+05s (99.983%)
  Time in thunks: 9.826846e+05s (99.364%)
  Total compile time: 8.077022e+01s
    Number of Apply nodes: 912
    Theano Optimizer time: 3.913498e+01s
       Theano validate time: 1.362901e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.058028e+01s
       Import time 2.882925e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036429.660s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  90.8%    90.8%     892228.465s       1.19e+00s     Py  750000       5   theano.scan_module.scan_op.Scan
   2.3%    93.1%     22583.671s       9.41e-03s     C   2400000      16   theano.sandbox.cuda.blas.GpuCorrMM_gradWeights
   1.6%    94.7%     15444.170s       6.86e-03s     C   2250000      15   theano.sandbox.cuda.blas.GpuCorrMM_gradInputs
   1.6%    96.2%     15415.514s       6.42e-03s     C   2400000      16   theano.sandbox.cuda.blas.GpuCorrMM
   1.1%    97.3%     10327.905s       5.74e-03s     C   1800000      12   theano.sandbox.cuda.blas.GpuDot22
   1.0%    98.3%     9537.307s       3.76e-04s     C   25350000     172   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.6%    98.8%     5502.631s       7.64e-04s     C   7200000      48   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.3%    99.2%     3426.108s       3.81e-03s     C   900000       6   theano.sandbox.cuda.blas.GpuGemm
   0.3%    99.5%     3326.310s       1.01e-03s     C   3300000      22   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.1%    99.6%     1018.209s       3.57e-04s     C   2850000      19   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.1%    99.7%     910.538s       1.21e-03s     C   750000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMaxGrad
   0.1%    99.8%     858.245s       4.09e-04s     C   2100000      14   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.1%    99.9%     696.444s       1.72e-04s     C   4050000      27   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.0%    99.9%     449.916s       6.00e-04s     C   750000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.0%    99.9%     231.079s       3.85e-04s     C   600000       4   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.0%    99.9%     191.435s       3.55e-05s     Py  5400000      18   theano.ifelse.IfElse
   0.0%   100.0%     163.353s       4.69e-06s     C   34800000     232   theano.tensor.elemwise.Elemwise
   0.0%   100.0%      92.942s       8.98e-06s     C   10350000      69   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%      58.724s       5.59e-05s     C   1050000       7   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%      49.875s       6.79e-06s     C   7350000      49   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   ... (remaining 8 Classes account for   0.02%(171.71s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  72.1%    72.1%     708482.379s       4.72e+00s     Py    150000        1   for{gpu,grad_of_scan_fn}
  14.7%    86.8%     144642.832s       9.64e-01s     Py    150000        1   for{gpu,scan_fn}
   3.4%    90.2%     33245.893s       2.22e-01s     Py    150000        1   for{gpu,grad_of_scan_fn}
   2.3%    92.5%     22583.671s       9.41e-03s     C     2400000       16   GpuCorrMM_gradWeights{valid, (1, 1)}
   1.6%    94.1%     15444.170s       6.86e-03s     C     2250000       15   GpuCorrMM_gradInputs{valid, (1, 1)}
   1.6%    95.6%     15415.514s       6.42e-03s     C     2400000       16   GpuCorrMM{valid, (1, 1)}
   1.1%    96.7%     10327.905s       5.74e-03s     C     1800000       12   GpuDot22
   0.6%    97.3%     5738.761s       3.83e-02s     Py    150000        1   for{gpu,scan_fn}
   0.6%    97.8%     5502.631s       7.64e-04s     C     7200000       48   GpuContiguous
   0.3%    98.2%     3426.108s       3.81e-03s     C     900000        6   GpuGemm{inplace}
   0.3%    98.5%     2645.533s       3.67e-04s     C     7200000       48   GpuElemwise{Add}[(0, 0)]
   0.2%    98.7%     2170.758s       1.61e-03s     C     1350000        9   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   0.2%    98.9%     1946.447s       6.49e-04s     C     3000000       20   GpuElemwise{add,no_inplace}
   0.2%    99.0%     1632.312s       6.80e-04s     C     2400000       16   GpuElemwise{Composite{((i0 * i1) + (i0 * i1 * sgn(i2)))}}[(0, 1)]
   0.2%    99.2%     1625.941s       6.77e-04s     C     2400000       16   GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}
   0.1%    99.3%     1076.047s       1.02e-03s     C     1050000        7   GpuIncSubtensor{Set;::, ::, int64:int64:, int64:int64:}
   0.1%    99.4%     967.346s       3.79e-04s     C     2550000       17   GpuAlloc{memset_0=True}
   0.1%    99.5%     910.538s       1.21e-03s     C     750000        5   GpuDownsampleFactorMaxGrad{(2, 2),True}
   0.1%    99.6%     858.245s       4.09e-04s     C     2100000       14   GpuFromHost
   0.1%    99.7%     827.744s       1.49e-04s     C     5550000       37   GpuElemwise{Composite{((i0 * i1) - (i2 * i3))}}[(0, 1)]
   ... (remaining 88 Ops account for   0.33%(3213.78s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  72.1%    72.1%     708482.379s       4.72e+00s   150000   697   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{Add}[(0, 0)].0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
  14.7%    86.8%     144642.832s       9.64e-01s   150000   355   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   3.4%    90.2%     33245.893s       2.22e-01s   150000   626   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   0.6%    90.8%     5738.761s       3.83e-02s   150000   552   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.5%    91.2%     4507.065s       3.00e-02s   150000   892   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.4%    91.6%     3687.262s       2.46e-02s   150000   904   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    92.0%     3389.767s       2.26e-02s   150000   688   GpuDot22(GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))}}[(0, 2)].0, GpuDimShuffle{1,0}.0)
   0.3%    92.3%     3305.832s       2.20e-02s   150000   361   GpuDot22(GpuReshape{2}.0, dense_4_W)
   0.3%    92.6%     2589.036s       1.73e-02s   150000   891   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.8%     2335.302s       1.56e-02s   150000   690   GpuGemm{inplace}(<CudaNdarrayType(float32, matrix)>, HostFromGpu.0, GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))}}[(0, 2)].0, HostFromGpu.0)
   0.2%    93.0%     2014.765s       1.34e-02s   150000   246   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    93.2%     1976.026s       1.32e-02s   150000   864   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    93.4%     1720.113s       1.15e-02s   150000   865   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    93.5%     1593.626s       1.06e-02s   150000   825   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    93.7%     1593.259s       1.06e-02s   150000   812   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    93.9%     1590.106s       1.06e-02s   150000   838   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    94.0%     1405.646s       9.37e-03s   150000   693   GpuElemwise{Add}[(0, 0)](dense_4_W, GpuGemm{inplace}.0)
   0.1%    94.2%     1386.329s       9.24e-03s   150000   878   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    94.3%     1333.872s       8.89e-03s   150000   328   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    94.4%     1333.645s       8.89e-03s   150000   323   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   ... (remaining 892 Apply instances account for 5.58%(54813.03s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 150000 calls of the op (for a total of 150000 steps) 1.445773e+05s

  Total time spent in calling the VM 1.443628e+05s (99.852%)
  Total overhead (computing slices..) 2.144716e+02s (0.148%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%     144319.287s       9.62e-01s     Py  150000       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%      10.239s       1.71e-05s     C   600000       4   theano.tensor.elemwise.Elemwise
   0.0%   100.0%      10.149s       6.77e-05s     C   150000       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       2.926s       6.50e-06s     C   450000       3   theano.compile.ops.Shape_i
   0.0%   100.0%       1.803s       1.20e-05s     C   150000       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       1.651s       1.10e-05s     C   150000       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       1.207s       8.05e-06s     C   150000       1   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       1.200s       4.00e-06s     C   300000       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%     144319.287s       9.62e-01s     Py    150000        1   for{gpu,scan_fn}
   0.0%   100.0%      10.149s       6.77e-05s     C     150000        1   HostFromGpu
   0.0%   100.0%       4.947s       3.30e-05s     C     150000        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       3.030s       2.02e-05s     C     150000        1   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}
   0.0%   100.0%       2.263s       7.54e-06s     C     300000        2   Elemwise{add,no_inplace}
   0.0%   100.0%       1.803s       1.20e-05s     C     150000        1   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       1.651s       1.10e-05s     C     150000        1   MakeVector{dtype='int64'}
   0.0%   100.0%       1.208s       8.05e-06s     C     150000        1   Shape_i{0}
   0.0%   100.0%       1.207s       8.05e-06s     C     150000        1   InplaceDimShuffle{x,0}
   0.0%   100.0%       1.200s       4.00e-06s     C     300000        2   ScalarFromTensor
   0.0%   100.0%       0.940s       6.27e-06s     C     150000        1   Shape_i{2}
   0.0%   100.0%       0.777s       5.18e-06s     C     150000        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%     144319.287s       9.62e-01s   150000    13   for{gpu,scan_fn}(Shape_i{0}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, Shape_i{0}.0, <CudaNdarrayType(float32, 3D)>, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.0%   100.0%      10.149s       6.77e-05s   150000    11   HostFromGpu(GpuSubtensor{int64:int64:int8}.0)
   0.0%   100.0%       4.947s       3.30e-05s   150000    12   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       3.030s       2.02e-05s   150000     7   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}(Shape_i{0}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       1.803s       1.20e-05s   150000    10   GpuSubtensor{int64:int64:int8}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       1.651s       1.10e-05s   150000     5   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       1.448s       9.65e-06s   150000     4   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{2}.0)
   0.0%   100.0%       1.208s       8.05e-06s   150000     2   Shape_i{0}(batch_of_rois[t][cuda])
   0.0%   100.0%       1.207s       8.05e-06s   150000     8   InplaceDimShuffle{x,0}(MakeVector{dtype='int64'}.0)
   0.0%   100.0%       0.940s       6.27e-06s   150000     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.815s       5.43e-06s   150000     3   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{1}.0)
   0.0%   100.0%       0.777s       5.18e-06s   150000     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.750s       5.00e-06s   150000     9   ScalarFromTensor(Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}.0)
   0.0%   100.0%       0.450s       3.00e-06s   150000     6   ScalarFromTensor(Shape_i{0}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 150000 calls of the op (for a total of 19982100 steps) 1.442162e+05s

  Total time spent in calling the VM 1.411722e+05s (97.889%)
  Total overhead (computing slices..) 3.044001e+03s (2.111%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  96.6%    96.6%     135804.125s       6.80e-03s     Py  19982100       1   theano.scan_module.scan_op.Scan
   1.8%    98.4%     2503.641s       1.25e-04s     C   19982100       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.9%    99.3%     1229.316s       2.05e-05s     Py  59946300       2   theano.ifelse.IfElse
   0.3%    99.5%     367.834s       1.31e-06s     C   279749400      14   theano.tensor.elemwise.Elemwise
   0.2%    99.7%     233.844s       5.85e-06s     C   39964200       2   theano.tensor.basic.Join
   0.1%    99.8%     165.099s       1.38e-06s     C   119892600       6   theano.tensor.subtensor.Subtensor
   0.0%    99.9%      62.183s       7.78e-07s     C   79928400       4   theano.tensor.basic.ScalarFromTensor
   0.0%    99.9%      57.925s       2.90e-06s     C   19982100       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%    99.9%      54.933s       1.37e-06s     C   39964200       2   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%      35.328s       1.77e-06s     C   19982100       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%      28.596s       7.16e-07s     C   39964200       2   theano.compile.ops.Shape_i
   0.0%   100.0%      28.234s       7.06e-07s     C   39964200       2   theano.tensor.opt.MakeVector
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  96.6%    96.6%     135804.125s       6.80e-03s     Py    19982100        1   for{gpu,scan_fn}
   1.8%    98.4%     2503.641s       1.25e-04s     C     19982100        1   GpuReshape{1}
   0.9%    99.3%     1229.316s       2.05e-05s     Py    59946300        2   if{inplace}
   0.2%    99.4%     233.844s       5.85e-06s     C     39964200        2   Join
   0.1%    99.5%     113.036s       1.41e-06s     C     79928400        4   Subtensor{int64}
   0.1%    99.6%      89.645s       1.12e-06s     C     79928400        4   Elemwise{add,no_inplace}
   0.1%    99.6%      74.989s       1.88e-06s     C     39964200        2   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}
   0.0%    99.7%      62.183s       7.78e-07s     C     79928400        4   ScalarFromTensor
   0.0%    99.7%      58.813s       1.47e-06s     C     39964200        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%    99.8%      57.925s       2.90e-06s     C     19982100        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   0.0%    99.8%      57.263s       1.43e-06s     C     39964200        2   Elemwise{clip,no_inplace}
   0.0%    99.8%      54.933s       1.37e-06s     C     39964200        2   InplaceDimShuffle{x}
   0.0%    99.9%      52.063s       1.30e-06s     C     39964200        2   Subtensor{int64::}
   0.0%    99.9%      51.897s       1.30e-06s     C     39964200        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.0%    99.9%      35.328s       1.77e-06s     C     19982100        1   GpuDimShuffle{2,0,1}
   0.0%   100.0%      35.227s       8.81e-07s     C     39964200        2   Elemwise{eq,no_inplace}
   0.0%   100.0%      28.234s       7.06e-07s     C     39964200        2   MakeVector{dtype='int64'}
   0.0%   100.0%      14.985s       7.50e-07s     C     19982100        1   Shape_i{1}
   0.0%   100.0%      13.611s       6.81e-07s     C     19982100        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  96.6%    96.6%     135804.125s       6.80e-03s   19982100    35   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Join.0, TensorConstant{7}, GpuSubtensor{::, int64:int64:, int64:int64:}.0, Join.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
   1.8%    98.4%     2503.641s       1.25e-04s   19982100    37   GpuReshape{1}(GpuDimShuffle{2,0,1}.0, TensorConstant{(1,) of -1})
   0.5%    98.9%     766.015s       3.83e-05s   19982100    17   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.3%    99.3%     463.301s       1.16e-05s   39964200    16   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.1%    99.4%     137.627s       6.89e-06s   19982100    34   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.1%    99.4%      96.216s       4.82e-06s   19982100    33   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.0%    99.5%      57.925s       2.90e-06s   19982100    24   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%    99.5%      54.327s       2.72e-06s   19982100     5   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.0%    99.5%      48.798s       2.44e-06s   19982100    30   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.6%      38.128s       1.91e-06s   19982100     7   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.0%    99.6%      35.328s       1.77e-06s   19982100    36   GpuDimShuffle{2,0,1}(for{gpu,scan_fn}.0)
   0.0%    99.6%      35.118s       1.76e-06s   19982100    21   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Compos
   0.0%    99.6%      34.329s       1.72e-06s   19982100     9   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   0.0%    99.7%      30.764s       1.54e-06s   19982100    32   Subtensor{int64::}(Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Constant{1})
   0.0%    99.7%      30.120s       1.51e-06s   19982100    26   InplaceDimShuffle{x}(Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0,
   0.0%    99.7%      29.734s       1.49e-06s   19982100    28   Elemwise{add,no_inplace}(TensorConstant{(1,) of -1}, InplaceDimShuffle{x}.0)
   0.0%    99.7%      26.447s       1.32e-06s   19982100    14   Elemwise{add,no_inplace}(TensorConstant{-1}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   0.0%    99.7%      26.191s       1.31e-06s   19982100    29   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.8%      25.305s       1.27e-06s   19982100     1   Subtensor{int64}(<TensorType(int64, vector)>, Constant{2})
   0.0%    99.8%      24.813s       1.24e-06s   19982100    22   InplaceDimShuffle{x}(Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0,
   ... (remaining 18 Apply instances account for 0.22%(302.81s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 19982100 calls of the op (for a total of 139874700 steps) 1.339498e+05s

  Total time spent in calling the VM 1.288988e+05s (96.229%)
  Total overhead (computing slices..) 5.051002e+03s (3.771%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.2%    99.2%     126816.028s       9.07e-04s     Py  139874700       1   theano.scan_module.scan_op.Scan
   0.3%    99.5%     375.604s       1.34e-06s     C   279749400       2   theano.tensor.elemwise.Elemwise
   0.2%    99.7%     238.544s       8.53e-07s     C   279749400       2   theano.tensor.basic.ScalarFromTensor
   0.2%    99.9%     191.683s       6.85e-07s     C   279749400       2   theano.compile.ops.Shape_i
   0.1%   100.0%     160.984s       1.15e-06s     C   139874700       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.2%    99.2%     126816.028s       9.07e-04s     Py    139874700        1   for{gpu,scan_fn}
   0.2%    99.4%     246.771s       1.76e-06s     C     139874700        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.2%    99.6%     238.544s       8.53e-07s     C     279749400        2   ScalarFromTensor
   0.1%    99.7%     160.984s       1.15e-06s     C     139874700        1   InplaceDimShuffle{x}
   0.1%    99.8%     128.833s       9.21e-07s     C     139874700        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)]
   0.1%    99.9%     113.853s       8.14e-07s     C     139874700        1   Shape_i{2}
   0.1%   100.0%      77.830s       5.56e-07s     C     139874700        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.2%    99.2%     126816.028s       9.07e-04s   139874700     7   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, <TensorType(int64, vector)>, TensorConstant{7}, <CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0)
   0.2%    99.4%     246.771s       1.76e-06s   139874700     6   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(<TensorType(int64, vector)>, TensorConstant{(1,) of 1}, <TensorType(int64, vector)>, InplaceDimShuffle{x}.0)
   0.1%    99.6%     189.720s       1.36e-06s   139874700     2   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.1%    99.7%     160.984s       1.15e-06s   139874700     4   InplaceDimShuffle{x}(Shape_i{2}.0)
   0.1%    99.8%     128.833s       9.21e-07s   139874700     3   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)](<TensorType(int64, scalar)>, TensorConstant{1}, <TensorType(int64, scalar)>, Shape_i{1}.0)
   0.1%    99.9%     113.853s       8.14e-07s   139874700     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.1%   100.0%      77.830s       5.56e-07s   139874700     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%      48.825s       3.49e-07s   139874700     5   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 139874700 calls of the op (for a total of 979122900 steps) 1.110998e+05s

  Total time spent in calling the VM 7.830440e+04s (70.481%)
  Total overhead (computing slices..) 3.279541e+04s (29.519%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  95.3%    95.3%     68929.553s       3.52e-05s     C   1958245800       2   theano.sandbox.cuda.basic_ops.GpuCAReduce
   2.7%    98.0%     1924.119s       1.97e-06s     C   979122900       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   2.0%   100.0%     1477.419s       7.54e-07s     C   1958245800       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.8%    52.8%     38160.553s       3.90e-05s     C     979122900        1   GpuCAReduce{maximum}{0,0,1}
  42.5%    95.3%     30769.000s       3.14e-05s     C     979122900        1   GpuCAReduce{maximum}{0,1}
   2.7%    98.0%     1924.119s       1.97e-06s     C     979122900        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   2.0%   100.0%     1477.419s       7.54e-07s     C     1958245800        2   ScalarFromTensor
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.8%    52.8%     38160.553s       3.90e-05s   979122900     3   GpuCAReduce{maximum}{0,0,1}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
  42.5%    95.3%     30769.000s       3.14e-05s   979122900     4   GpuCAReduce{maximum}{0,1}(GpuCAReduce{maximum}{0,0,1}.0)
   2.7%    98.0%     1924.119s       1.97e-06s   979122900     2   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
   1.6%    99.6%     1180.559s       1.21e-06s   979122900     1   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.4%   100.0%     296.860s       3.03e-07s   979122900     0   ScalarFromTensor(<TensorType(int64, scalar)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 150000 calls of the op (for a total of 150000 steps) 5.693031e+03s

  Total time spent in calling the VM 5.644407e+03s (99.146%)
  Total overhead (computing slices..) 4.862399e+01s (0.854%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.7%    99.7%     5616.140s       3.74e-02s     Py  150000       1   theano.scan_module.scan_op.Scan
   0.1%    99.8%       6.976s       4.65e-06s     C   1500000      10   theano.tensor.elemwise.Elemwise
   0.1%    99.9%       6.364s       2.12e-05s     C   300000       2   theano.compile.ops.Shape_i
   0.0%   100.0%       1.919s       6.40e-06s     C   300000       2   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.931s       1.55e-06s     C   600000       4   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.7%    99.7%     5616.140s       3.74e-02s     Py    150000        1   for{gpu,scan_fn}
   0.1%    99.8%       6.364s       2.12e-05s     C     300000        2   Shape_i{0}
   0.0%    99.9%       1.940s       6.47e-06s     C     300000        2   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   0.0%    99.9%       1.919s       6.40e-06s     C     300000        2   GpuSubtensor{int64:int64:int8}
   0.0%    99.9%       1.532s       5.11e-06s     C     300000        2   Elemwise{switch,no_inplace}
   0.0%    99.9%       1.283s       4.28e-06s     C     300000        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   0.0%   100.0%       1.157s       7.71e-06s     C     150000        1   Elemwise{lt,no_inplace}
   0.0%   100.0%       0.931s       1.55e-06s     C     600000        4   ScalarFromTensor
   0.0%   100.0%       0.561s       1.87e-06s     C     300000        2   Elemwise{le,no_inplace}
   0.0%   100.0%       0.504s       3.36e-06s     C     150000        1   Elemwise{minimum,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.7%    99.7%     5616.140s       3.74e-02s   150000    18   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.1%    99.8%       5.332s       3.55e-05s   150000     0   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.0%    99.8%       1.639s       1.09e-05s   150000    10   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%    99.9%       1.360s       9.07e-06s   150000    11   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%    99.9%       1.349s       8.99e-06s   150000    17   GpuSubtensor{int64:int64:int8}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%    99.9%       1.157s       7.71e-06s   150000     3   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%    99.9%       1.032s       6.88e-06s   150000     1   Shape_i{0}(bbox_output_target[t][cuda])
   0.0%    99.9%       0.650s       4.33e-06s   150000     5   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%    99.9%       0.633s       4.22e-06s   150000     4   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.570s       3.80e-06s   150000    16   GpuSubtensor{int64:int64:int8}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.504s       3.36e-06s   150000     2   Elemwise{minimum,no_inplace}(Shape_i{0}.0, Shape_i{0}.0)
   0.0%   100.0%       0.442s       2.94e-06s   150000     7   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.378s       2.52e-06s   150000    15   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.330s       2.20e-06s   150000    13   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.301s       2.01e-06s   150000     8   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.172s       1.14e-06s   150000     9   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.122s       8.16e-07s   150000    12   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.119s       7.94e-07s   150000     6   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.100s       6.69e-07s   150000    14   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 150000 calls of the op (for a total of 19982100 steps) 5.530419e+03s

  Total time spent in calling the VM 4.632650e+03s (83.767%)
  Total overhead (computing slices..) 8.977694e+02s (16.233%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  43.8%    43.8%     1868.931s       1.98e-05s     Py  94449150       5   theano.ifelse.IfElse
  27.1%    70.8%     1156.367s       3.06e-05s     C   37744408      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  25.9%    96.7%     1103.856s       3.00e-05s     C   36746700       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   2.0%    98.7%      85.959s       1.61e-06s     C   53511300       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   1.0%    99.7%      41.889s       1.14e-06s     C   36746700       5   theano.tensor.elemwise.Elemwise
   0.3%   100.0%      13.172s       6.59e-07s     C   19982100       1   theano.compile.ops.ViewOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.8%    43.8%     1868.931s       1.98e-05s     Py    94449150        5   if{inplace,gpu}
  25.9%    69.6%     1103.856s       3.00e-05s     C     36746700        5   HostFromGpu
  12.1%    81.7%     516.940s       3.08e-05s     C     16764600        4   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}
  12.1%    93.8%     515.073s       3.07e-05s     C     16764600        4   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}
   2.9%    96.7%     123.664s       2.95e-05s     C     4191150        1   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)]
   2.0%    98.7%      85.959s       1.61e-06s     C     53511300        9   GpuSubtensor{int64}
   0.5%    99.2%      22.082s       1.11e-06s     C     19982100        1   Elemwise{eq,no_inplace}
   0.5%    99.7%      19.807s       1.18e-06s     C     16764600        4   Elemwise{lt,no_inplace}
   0.3%   100.0%      13.172s       6.59e-07s     C     19982100        1   ViewOp
   0.0%   100.0%       0.689s       2.86e-05s     C     24058        4   GpuElemwise{Add}[(0, 1)]
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  27.0%    27.0%     1154.006s       2.61e-05s   44155350    36   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)].0)
  14.7%    41.8%     629.516s       3.15e-05s   19982100     9   HostFromGpu(GpuSubtensor{int64}.0)
   4.2%    46.0%     179.819s       1.43e-05s   12573450    34   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   4.2%    50.2%     178.778s       1.42e-05s   12573450    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   4.2%    54.3%     178.451s       1.42e-05s   12573450    32   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   4.2%    58.5%     177.878s       1.41e-05s   12573450    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   3.2%    61.7%     136.045s       3.25e-05s   4191150    10   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   3.1%    64.8%     132.086s       3.15e-05s   4191150    15   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   3.0%    67.8%     128.864s       3.07e-05s   4191150    21   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   3.0%    70.8%     128.201s       3.06e-05s   4191150    17   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   3.0%    73.8%     127.790s       3.05e-05s   4191150    19   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   3.0%    76.8%     127.465s       3.04e-05s   4191150    13   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   3.0%    79.7%     126.058s       3.01e-05s   4191150    12   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.9%    82.7%     125.506s       2.99e-05s   4191150    11   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   2.9%    85.6%     123.664s       2.95e-05s   4191150    35   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)](if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0)
   2.8%    88.4%     119.392s       2.85e-05s   4191150    16   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.8%    91.1%     118.428s       2.83e-05s   4191150    22   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.8%    93.9%     118.371s       2.82e-05s   4191150    20   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.8%    96.7%     118.148s       2.82e-05s   4191150    18   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   0.9%    97.6%      40.218s       2.01e-06s   19982100     1   GpuSubtensor{int64}(bbox_output_target[t][t][cuda], Constant{0})
   ... (remaining 18 Apply instances account for 2.38%(101.49s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 150000 calls of the op (for a total of 150000 steps) 8.732612e+01s

  Total time spent in calling the VM 3.370697e+01s (38.599%)
  Total overhead (computing slices..) 5.361915e+01s (61.401%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  55.3%    55.3%      17.029s       1.14e-04s     C   150000       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
  44.7%   100.0%      13.774s       9.18e-05s     C   150000       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  55.3%    55.3%      17.029s       1.14e-04s     C     150000        1   GpuCAReduce{add}{0,1}
  44.7%   100.0%      13.774s       9.18e-05s     C     150000        1   GpuElemwise{neg,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  55.3%    55.3%      17.029s       1.14e-04s   150000     0   GpuCAReduce{add}{0,1}(<CudaNdarrayType(float32, matrix)>)
  44.7%   100.0%      13.774s       9.18e-05s   150000     1   GpuElemwise{neg,no_inplace}(GpuCAReduce{add}{0,1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 150000 calls of the op (for a total of 150000 steps) 3.310348e+04s

  Total time spent in calling the VM 3.305325e+04s (99.848%)
  Total overhead (computing slices..) 5.023828e+01s (0.152%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.6%    99.6%     32893.329s       2.19e-01s     Py  150000       1   theano.scan_module.scan_op.Scan
   0.2%    99.8%      52.281s       6.58e-06s     C   7950000      53   theano.tensor.elemwise.Elemwise
   0.1%    99.9%      24.428s       8.14e-05s     C   300000       2   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.1%    99.9%      23.440s       7.81e-05s     C   300000       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.0%   100.0%       6.104s       5.81e-06s     C   1050000       7   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       6.080s       1.01e-05s     C   600000       4   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       4.333s       5.78e-06s     C   750000       5   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.6%    99.6%     32893.329s       2.19e-01s     Py    150000        1   for{gpu,grad_of_scan_fn}
   0.1%    99.7%      23.440s       7.81e-05s     C     300000        2   GpuAlloc{memset_0=True}
   0.1%    99.8%      17.334s       1.16e-04s     C     150000        1   GpuIncSubtensor{Inc;int64::}
   0.0%    99.8%       7.593s       2.53e-05s     C     300000        2   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7),
   0.0%    99.8%       7.094s       4.73e-05s     C     150000        1   GpuIncSubtensor{InplaceInc;:int64:}
   0.0%    99.8%       6.380s       6.08e-06s     C     1050000        7   Elemwise{add,no_inplace}
   0.0%    99.9%       6.104s       5.81e-06s     C     1050000        7   ScalarFromTensor
   0.0%    99.9%       3.730s       6.22e-06s     C     600000        4   Shape_i{0}
   0.0%    99.9%       3.620s       8.04e-06s     C     450000        3   GpuSubtensor{int64:int64:int64}
   0.0%    99.9%       3.405s       3.78e-06s     C     900000        6   Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}
   0.0%    99.9%       3.231s       3.59e-06s     C     900000        6   Elemwise{sub,no_inplace}
   0.0%    99.9%       3.210s       1.07e-05s     C     300000        2   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)]
   0.0%    99.9%       3.063s       2.92e-06s     C     1050000        7   Elemwise{le,no_inplace}
   0.0%    99.9%       2.957s       9.86e-06s     C     300000        2   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i2 + i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}}[(0, 3)]
   0.0%    99.9%       2.818s       9.39e-06s     C     300000        2   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3
   0.0%    99.9%       2.706s       6.01e-06s     C     450000        3   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}
   0.0%    99.9%       2.460s       1.64e-05s     C     150000        1   GpuSubtensor{::int64}
   0.0%   100.0%       2.241s       7.47e-06s     C     300000        2   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}}[(0, 3)]
   0.0%   100.0%       2.150s       7.17e-06s     C     300000        2   Elemwise{Add}[(0, 1)]
   0.0%   100.0%       2.018s       6.73e-06s     C     300000        2   Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}[(0, 3)]
   ... (remaining 9 Ops account for   0.03%(11.11s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.6%    99.6%     32893.329s       2.19e-01s   150000    70   for{gpu,grad_of_scan_fn}(Shape_i{0}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   0.1%    99.7%      17.334s       1.16e-04s   150000    73   GpuIncSubtensor{Inc;int64::}(<CudaNdarrayType(float32, matrix)>, GpuIncSubtensor{InplaceInc;:int64:}.0, Constant{0})
   0.0%    99.7%      12.841s       8.56e-05s   150000     6   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[ 0.]]}, Shape_i{0}.0, Shape_i{1}.0)
   0.0%    99.8%      10.599s       7.07e-05s   150000    45   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[ 0.]]}, Elemwise{Sub}[(0, 0)].0, Shape_i{1}.0)
   0.0%    99.8%       7.094s       4.73e-05s   150000    72   GpuIncSubtensor{InplaceInc;:int64:}(GpuAlloc{memset_0=True}.0, GpuSubtensor{::int64}.0, ScalarFromTensor.0)
   0.0%    99.8%       5.407s       3.60e-05s   150000    41   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i
   0.0%    99.8%       3.628s       2.42e-05s   150000    11   ScalarFromTensor(Elemwise{minimum,no_inplace}.0)
   0.0%    99.8%       2.565s       1.71e-05s   150000    34   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(Composit
   0.0%    99.8%       2.460s       1.64e-05s   150000    71   GpuSubtensor{::int64}(for{gpu,grad_of_scan_fn}.0, Constant{-1})
   0.0%    99.8%       2.427s       1.62e-05s   150000    49   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7), i6), (i2 + i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i6), i1, i7))}}[(0, 3)](Elemwise{le,no_inpla
   0.0%    99.8%       2.361s       1.57e-05s   150000    55   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Co
   0.0%    99.9%       2.186s       1.46e-05s   150000    40   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i
   0.0%    99.9%       1.837s       1.22e-05s   150000    62   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}}[(0, 3)](Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{-1}, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (
   0.0%    99.9%       1.740s       1.16e-05s   150000    12   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%    99.9%       1.725s       1.15e-05s   150000    27   Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}(Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}}.0)
   0.0%    99.9%       1.607s       1.07e-05s   150000    36   Elemwise{add,no_inplace}(TensorConstant{1}, Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}[(0, 6)].0)
   0.0%    99.9%       1.602s       1.07e-05s   150000    63   Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}[(0, 3)](Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{-1}, Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%    99.9%       1.552s       1.03e-05s   150000    17   Elemwise{add,no_inplace}(TensorConstant{-1}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0)
   0.0%    99.9%       1.540s       1.03e-05s   150000    69   GpuSubtensor{int64:int64:int64}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.0%    99.9%       1.537s       1.02e-05s   150000    22   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 - i3), i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), (i2 - i3))))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{add,no_inplace}.0, Elemwise{Composite{Switch(LT(i0, (i1 - i2)), i0, (i1 - i2))}}.0, TensorConstant{-1}, Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0)
   ... (remaining 54 Apply instances account for 0.10%(34.62s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 150000 calls of the op (for a total of 19982100 steps) 3.277539e+04s

  Total time spent in calling the VM 3.006015e+04s (91.716%)
  Total overhead (computing slices..) 2.715246e+03s (8.284%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  46.2%    46.2%     13304.576s       4.44e-05s     Py  299731500       9   theano.ifelse.IfElse
  29.8%    76.0%     8565.747s       3.30e-05s     C   259767300      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  12.4%    88.4%     3572.854s       4.47e-05s     C   79928400       4   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
  10.2%    98.7%     2945.710s       2.95e-05s     C   99910500       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.9%    99.6%     260.856s       1.45e-06s     C   179838900       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.4%   100.0%     121.329s       1.21e-06s     C   99910500       5   theano.tensor.elemwise.Elemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  36.5%    36.5%     10509.538s       5.85e-05s     Py    179789148        4   if{gpu}
  14.8%    51.3%     4260.795s       5.33e-05s     C     79928400        4   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)]
  10.2%    61.6%     2945.710s       2.95e-05s     C     99910500        5   HostFromGpu
   9.7%    71.3%     2795.038s       2.33e-05s     Py    119942352        5   if{inplace,gpu}
   6.9%    78.2%     1990.480s       2.49e-05s     C     79928400        4   GpuElemwise{sub,no_inplace}
   6.5%    84.7%     1865.459s       9.34e-05s     C     19982100        1   GpuIncSubtensor{Inc;int64}
   6.0%    90.7%     1734.258s       2.17e-05s     C     79928400        4   GpuElemwise{Abs,no_inplace}
   5.9%    96.7%     1707.395s       2.85e-05s     C     59946300        3   GpuIncSubtensor{InplaceInc;int64}
   2.0%    98.7%     580.214s       2.90e-05s     C     19982100        1   GpuElemwise{Composite{(i0 + (i0 + (i0 + i0)))},no_inplace}
   0.9%    99.6%     260.856s       1.45e-06s     C     179838900        9   GpuSubtensor{int64}
   0.3%    99.9%      95.172s       1.19e-06s     C     79928400        4   Elemwise{lt,no_inplace}
   0.1%   100.0%      26.157s       1.31e-06s     C     19982100        1   Elemwise{eq,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
   9.8%     9.8%     2833.803s       4.73e-05s   59896548    36   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   8.9%    18.8%     2564.509s       6.42e-05s   39964200    34   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   8.9%    27.7%     2557.555s       6.40e-05s   39964200    32   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   8.9%    36.5%     2553.670s       6.39e-05s   39964200    30   if{gpu}(Elemwise{lt,no_inplace}.0, if{inplace,gpu}.0, CudaNdarrayConstant{0.0})
   6.5%    43.0%     1865.459s       9.34e-05s   19982100    44   GpuIncSubtensor{Inc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{3})
   3.7%    46.7%     1070.910s       5.36e-05s   19982100    40   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   3.7%    50.4%     1064.188s       5.33e-05s   19982100    39   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   3.7%    54.1%     1063.735s       5.32e-05s   19982100    37   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   3.7%    57.8%     1061.962s       5.31e-05s   19982100    38   GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)](CudaNdarrayConstant{0.5}, if{gpu}.0, GpuElemwise{Abs,no_inplace}.0, if{inplace,gpu}.0, GpuElemwise{sub,no_inplace}.0)
   3.3%    61.1%     956.805s       2.39e-05s   39964200    21   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, <CudaNdarrayType(float32, scalar)>)
   2.1%    63.3%     605.495s       3.03e-05s   19982100    11   HostFromGpu(GpuSubtensor{int64}.0)
   2.1%    65.3%     595.145s       2.98e-05s   19982100    24   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   2.0%    67.3%     582.547s       2.92e-05s   19982100    22   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   2.0%    69.4%     581.377s       2.91e-05s   19982100    20   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   2.0%    71.4%     581.146s       2.91e-05s   19982100    23   HostFromGpu(GpuElemwise{Abs,no_inplace}.0)
   2.0%    73.4%     580.214s       2.90e-05s   19982100     9   GpuElemwise{Composite{(i0 + (i0 + (i0 + i0)))},no_inplace}(<CudaNdarrayType(float32, vector)>)
   2.0%    75.4%     571.960s       2.86e-05s   19982100    41   GpuIncSubtensor{InplaceInc;int64}(GpuElemwise{Composite{(i0 + (i0 + (i0 + i0)))},no_inplace}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{0})
   2.0%    77.4%     567.986s       2.84e-05s   19982100    42   GpuIncSubtensor{InplaceInc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{1})
   2.0%    79.3%     567.450s       2.84e-05s   19982100    43   GpuIncSubtensor{InplaceInc;int64}(GpuIncSubtensor{InplaceInc;int64}.0, GpuElemwise{Composite{(((i0 * i1 * i2) + (i0 * i1 * i2) + i3) * sgn(i4))}}[(0, 1)].0, Constant{2})
   1.7%    81.1%     502.805s       2.52e-05s   19982100    14   GpuElemwise{sub,no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   ... (remaining 25 Apply instances account for 18.92%(5442.35s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 150000 calls of the op (for a total of 150000 steps) 7.083434e+05s

  Total time spent in calling the VM 7.082859e+05s (99.992%)
  Total overhead (computing slices..) 5.752789e+01s (0.008%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%     708097.511s       4.72e+00s     Py  150000       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%      75.966s       2.53e-04s     C   300000       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.0%   100.0%      43.139s       2.88e-04s     C   150000       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%      36.929s       7.24e-06s     C   5100000      34   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       3.436s       3.82e-06s     C   900000       6   theano.compile.ops.Shape_i
   0.0%   100.0%       2.768s       6.15e-06s     C   450000       3   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       2.342s       3.12e-06s     C   750000       5   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       1.172s       7.81e-06s     C   150000       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.979s       6.53e-06s     C   150000       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%     708097.511s       4.72e+00s     Py    150000        1   forall_inplace,gpu,grad_of_scan_fn}
   0.0%   100.0%      75.966s       2.53e-04s     C     300000        2   GpuAlloc{memset_0=True}
   0.0%   100.0%      43.139s       2.88e-04s     C     150000        1   HostFromGpu
   0.0%   100.0%       4.570s       3.05e-05s     C     150000        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       3.753s       2.50e-05s     C     150000        1   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}
   0.0%   100.0%       3.513s       3.35e-06s     C     1050000        7   Elemwise{add,no_inplace}
   0.0%   100.0%       2.741s       1.83e-05s     C     150000        1   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}
   0.0%   100.0%       2.454s       1.64e-05s     C     150000        1   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), 
   0.0%   100.0%       2.342s       3.12e-06s     C     750000        5   ScalarFromTensor
   0.0%   100.0%       2.201s       1.47e-05s     C     150000        1   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6), i4), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6))}}[(0, 3)]
   0.0%   100.0%       2.155s       1.44e-05s     C     150000        1   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i8), i3, i9), i8), i3), i3, i1), i3)
   0.0%   100.0%       2.121s       1.41e-05s     C     150000        1   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)]
   0.0%   100.0%       1.893s       3.16e-06s     C     600000        4   Shape_i{0}
   0.0%   100.0%       1.830s       1.22e-05s     C     150000        1   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)]
   0.0%   100.0%       1.518s       5.06e-06s     C     300000        2   GpuSubtensor{int64:int64:int64}
   0.0%   100.0%       1.486s       2.48e-06s     C     600000        4   Elemwise{le,no_inplace}
   0.0%   100.0%       1.293s       4.31e-06s     C     300000        2   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}
   0.0%   100.0%       1.273s       2.83e-06s     C     450000        3   Elemwise{sub,no_inplace}
   0.0%   100.0%       1.250s       8.33e-06s     C     150000        1   GpuSubtensor{int64}
   0.0%   100.0%       1.241s       8.28e-06s     C     150000        1   Shape_i{2}
   ... (remaining 12 Ops account for   0.00%(9.99s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%     708097.511s       4.72e+00s   150000    52   forall_inplace,gpu,grad_of_scan_fn}(Elemwise{maximum,no_inplace}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, <CudaNdarrayType(float32, 3D)>, GpuAlloc{memset_0=True}.0, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.0%   100.0%      55.266s       3.68e-04s   150000    28   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)].0, Shape_
   0.0%   100.0%      43.139s       2.88e-04s   150000    50   HostFromGpu(GpuSubtensor{int64:int64:int64}.0)
   0.0%   100.0%      20.699s       1.38e-04s   150000    11   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0)
   0.0%   100.0%       4.570s       3.05e-05s   150000    51   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       3.753s       2.50e-05s   150000     7   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}(TensorConstant{1}, TensorConstant{-1}, Shape_i{0}.0)
   0.0%   100.0%       2.741s       1.83e-05s   150000    23   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}}(Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)
   0.0%   100.0%       2.454s       1.64e-05s   150000    32   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3
   0.0%   100.0%       2.201s       1.47e-05s   150000    39   Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6), i4), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}(i0, i1, i2, i3, i4, i5), i1, i4), i1, i6))}}[(0, 3)](Elemwise{le,no_inplace}.0, 
   0.0%   100.0%       2.155s       1.44e-05s   150000    42   Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, minimum(i2, i5)))}(i2, i3, (i4 + i5), i6, i7, i8), i3, i8), i3, i9), i8), i3), i3, i1), i3), i10), Com
   0.0%   100.0%       2.121s       1.41e-05s   150000    22   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)](Elemwise{add,no_inplace}.0, Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}.0, TensorConstant{1}, TensorConstant{1}, Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2})
   0.0%   100.0%       1.830s       1.22e-05s   150000    24   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)](Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2},
   0.0%   100.0%       1.250s       8.33e-06s   150000    53   GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.0, ScalarFromTensor.0)
   0.0%   100.0%       1.241s       8.28e-06s   150000     2   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       1.226s       8.17e-06s   150000    25   ScalarFromTensor(Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)].0)
   0.0%   100.0%       1.172s       7.81e-06s   150000    10   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       1.155s       7.70e-06s   150000    17   Elemwise{maximum,no_inplace}(Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}.0, TensorConstant{1})
   0.0%   100.0%       1.016s       6.78e-06s   150000    20   Elemwise{Composite{((i0 - i1) + i2)}}(Elemwise{maximum,no_inplace}.0, Elemwise{add,no_inplace}.0, TensorConstant{1})
   0.0%   100.0%       0.999s       6.66e-06s   150000     6   Elemwise{add,no_inplace}(TensorConstant{-1}, TensorConstant{1}, Shape_i{0}.0)
   0.0%   100.0%       0.979s       6.53e-06s   150000    18   InplaceDimShuffle{x,0}(MakeVector{dtype='int64'}.0)
   ... (remaining 34 Apply instances account for 0.00%(16.76s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 150000 calls of the op (for a total of 19982100 steps) 7.079222e+05s

  Total time spent in calling the VM 7.048562e+05s (99.567%)
  Total overhead (computing slices..) 3.066053e+03s (0.433%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  98.9%    98.9%     696217.570s       1.74e-02s     Py  39964200       2   theano.scan_module.scan_op.Scan
   0.3%    99.2%     1852.908s       9.27e-05s     C   19982100       1   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.2%    99.4%     1453.918s       2.43e-05s     Py  59946300       2   theano.ifelse.IfElse
   0.2%    99.6%     1442.140s       7.22e-05s     C   19982100       1   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.1%    99.7%     758.296s       3.79e-05s     C   19982100       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.1%    99.8%     619.264s       7.75e-06s     C   79928400       4   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.1%    99.9%     487.602s       1.74e-06s     C   279749400      14   theano.tensor.elemwise.Elemwise
   0.1%    99.9%     428.948s       2.15e-06s     C   199821000      10   theano.tensor.subtensor.Subtensor
   0.0%    99.9%     244.295s       6.11e-06s     C   39964200       2   theano.tensor.basic.Join
   0.0%   100.0%      82.179s       4.11e-06s     C   19982100       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%      79.176s       9.91e-07s     C   79928400       4   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%      73.437s       1.23e-06s     C   59946300       3   theano.tensor.opt.MakeVector
   0.0%   100.0%      61.810s       1.55e-06s     C   39964200       2   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%      58.047s       9.68e-07s     C   59946300       3   theano.compile.ops.Shape_i
   0.0%   100.0%      26.851s       1.34e-06s     C   19982100       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  79.5%    79.5%     559409.492s       2.80e-02s     Py    19982100        1   forall_inplace,gpu,grad_of_scan_fn}
  19.4%    98.9%     136808.078s       6.85e-03s     Py    19982100        1   for{gpu,scan_fn}
   0.3%    99.2%     1852.908s       9.27e-05s     C     19982100        1   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}
   0.2%    99.4%     1453.918s       2.43e-05s     Py    59946300        2   if{inplace}
   0.2%    99.6%     1442.140s       7.22e-05s     C     19982100        1   GpuAlloc{memset_0=True}
   0.1%    99.7%     758.296s       3.79e-05s     C     19982100        1   GpuElemwise{add,no_inplace}
   0.1%    99.8%     430.145s       2.15e-05s     C     19982100        1   GpuSubtensor{int64}
   0.0%    99.8%     244.295s       6.11e-06s     C     39964200        2   Join
   0.0%    99.8%     219.739s       2.75e-06s     C     79928400        4   Subtensor{int64:int64:int64}
   0.0%    99.8%     154.269s       1.93e-06s     C     79928400        4   Subtensor{int64}
   0.0%    99.9%     134.861s       3.37e-06s     C     39964200        2   GpuSubtensor{int64:int64:int64}
   0.0%    99.9%     117.740s       2.95e-06s     C     39964200        2   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}
   0.0%    99.9%     108.967s       1.36e-06s     C     79928400        4   Elemwise{add,no_inplace}
   0.0%    99.9%      84.496s       2.11e-06s     C     39964200        2   Elemwise{clip,no_inplace}
   0.0%    99.9%      82.179s       4.11e-06s     C     19982100        1   GpuReshape{3}
   0.0%    99.9%      79.176s       9.91e-07s     C     79928400        4   ScalarFromTensor
   0.0%    99.9%      73.437s       1.23e-06s     C     59946300        3   MakeVector{dtype='int64'}
   0.0%    99.9%      69.938s       1.75e-06s     C     39964200        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%   100.0%      67.870s       1.70e-06s     C     39964200        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.0%   100.0%      61.810s       1.55e-06s     C     39964200        2   InplaceDimShuffle{x}
   ... (remaining 7 Ops account for   0.03%(232.69s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  79.5%    79.5%     559409.492s       2.80e-02s   19982100    48   forall_inplace,gpu,grad_of_scan_fn}(TensorConstant{7}, Subtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{::, int64:int64:, int64:int64:}.0, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2
  19.4%    98.9%     136808.078s       6.85e-03s   19982100    45   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Join.0, TensorConstant{7}, GpuSubtensor{::, int64:int64:, int64:int64:}.0, Join.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
   0.3%    99.2%     1852.908s       9.27e-05s   19982100    50   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}(GpuElemwise{add,no_inplace}.0, GpuSubtensor{int64}.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.2%    99.4%     1442.140s       7.22e-05s   19982100    31   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, TensorConstant{2}, Shape_i{0}.0, Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 +
   0.1%    99.5%     917.019s       4.59e-05s   19982100    22   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.1%    99.6%     758.296s       3.79e-05s   19982100     7   GpuElemwise{add,no_inplace}(<CudaNdarrayType(float32, 3D)>, <CudaNdarrayType(float32, 3D)>)
   0.1%    99.7%     536.899s       1.34e-05s   39964200    21   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.1%    99.8%     430.145s       2.15e-05s   19982100    49   GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.0, Constant{1})
   0.0%    99.8%     148.817s       7.45e-06s   19982100    43   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.0%    99.8%     103.950s       5.20e-06s   19982100    44   Subtensor{int64:int64:int64}(Join.0, Constant{6}, Constant{-8}, Constant{-1})
   0.0%    99.8%      95.478s       4.78e-06s   19982100    42   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.0%    99.8%      87.935s       4.40e-06s   19982100    47   GpuSubtensor{int64:int64:int64}(for{gpu,scan_fn}.0, Constant{6}, Constant{-8}, Constant{-1})
   0.0%    99.8%      84.231s       4.22e-06s   19982100     3   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.0%    99.8%      83.726s       4.19e-06s   19982100    37   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.9%      82.179s       4.11e-06s   19982100    13   GpuReshape{3}(<CudaNdarrayType(float32, vector)>, MakeVector{dtype='int64'}.0)
   0.0%    99.9%      58.300s       2.92e-06s   19982100    41   Subtensor{int64:int64:int64}(Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Constant{6}, Constant{-8}, Constant{-1})
   0.0%    99.9%      56.146s       2.81e-06s   19982100     9   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.0%    99.9%      54.258s       2.72e-06s   19982100    30   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%    99.9%      46.926s       2.35e-06s   19982100    23   GpuSubtensor{int64:int64:int64}(GpuDimShuffle{1,2,0}.0, Constant{6}, Constant{-8}, Constant{-1})
   0.0%    99.9%      46.265s       2.32e-06s   19982100    12   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   ... (remaining 31 Apply instances account for 0.11%(783.25s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 19982100 calls of the op (for a total of 139874700 steps) 1.348826e+05s

  Total time spent in calling the VM 1.297661e+05s (96.207%)
  Total overhead (computing slices..) 5.116433e+03s (3.793%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.2%    99.2%     127706.671s       9.13e-04s     Py  139874700       1   theano.scan_module.scan_op.Scan
   0.3%    99.5%     406.650s       1.45e-06s     C   279749400       2   theano.tensor.elemwise.Elemwise
   0.2%    99.7%     251.546s       8.99e-07s     C   279749400       2   theano.tensor.basic.ScalarFromTensor
   0.1%    99.9%     180.101s       6.44e-07s     C   279749400       2   theano.compile.ops.Shape_i
   0.1%   100.0%     164.390s       1.18e-06s     C   139874700       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.2%    99.2%     127706.671s       9.13e-04s     Py    139874700        1   for{gpu,scan_fn}
   0.2%    99.4%     258.620s       1.85e-06s     C     139874700        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.2%    99.6%     251.546s       8.99e-07s     C     279749400        2   ScalarFromTensor
   0.1%    99.7%     164.390s       1.18e-06s     C     139874700        1   InplaceDimShuffle{x}
   0.1%    99.9%     148.029s       1.06e-06s     C     139874700        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)]
   0.1%    99.9%      97.283s       6.96e-07s     C     139874700        1   Shape_i{2}
   0.1%   100.0%      82.818s       5.92e-07s     C     139874700        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.2%    99.2%     127706.671s       9.13e-04s   139874700     7   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, <TensorType(int64, vector)>, TensorConstant{7}, <CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0)
   0.2%    99.4%     258.620s       1.85e-06s   139874700     6   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(<TensorType(int64, vector)>, TensorConstant{(1,) of 1}, <TensorType(int64, vector)>, InplaceDimShuffle{x}.0)
   0.2%    99.6%     202.093s       1.44e-06s   139874700     2   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.1%    99.7%     164.390s       1.18e-06s   139874700     4   InplaceDimShuffle{x}(Shape_i{2}.0)
   0.1%    99.8%     148.029s       1.06e-06s   139874700     3   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)](<TensorType(int64, scalar)>, TensorConstant{1}, <TensorType(int64, scalar)>, Shape_i{1}.0)
   0.1%    99.9%      97.283s       6.96e-07s   139874700     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.1%   100.0%      82.818s       5.92e-07s   139874700     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%      49.452s       3.54e-07s   139874700     5   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 139874700 calls of the op (for a total of 979122900 steps) 1.120948e+05s

  Total time spent in calling the VM 7.885283e+04s (70.345%)
  Total overhead (computing slices..) 3.324194e+04s (29.655%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  95.5%    95.5%     69729.228s       3.56e-05s     C   1958245800       2   theano.sandbox.cuda.basic_ops.GpuCAReduce
   2.6%    98.0%     1873.337s       1.91e-06s     C   979122900       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   2.0%   100.0%     1428.610s       7.30e-07s     C   1958245800       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.6%    52.6%     38419.792s       3.92e-05s     C     979122900        1   GpuCAReduce{maximum}{0,0,1}
  42.9%    95.5%     31309.436s       3.20e-05s     C     979122900        1   GpuCAReduce{maximum}{0,1}
   2.6%    98.0%     1873.337s       1.91e-06s     C     979122900        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   2.0%   100.0%     1428.610s       7.30e-07s     C     1958245800        2   ScalarFromTensor
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.6%    52.6%     38419.792s       3.92e-05s   979122900     3   GpuCAReduce{maximum}{0,0,1}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
  42.9%    95.5%     31309.436s       3.20e-05s   979122900     4   GpuCAReduce{maximum}{0,1}(GpuCAReduce{maximum}{0,0,1}.0)
   2.6%    98.0%     1873.337s       1.91e-06s   979122900     2   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
   1.6%    99.6%     1143.810s       1.17e-06s   979122900     1   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.4%   100.0%     284.800s       2.91e-07s   979122900     0   ScalarFromTensor(<TensorType(int64, scalar)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 19982100 calls of the op (for a total of 139874700 steps) 5.521176e+05s

  Total time spent in calling the VM 5.381316e+05s (97.467%)
  Total overhead (computing slices..) 1.398608e+04s (2.533%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  96.0%    96.0%     513244.963s       3.67e-03s     Py  139874700       1   theano.scan_module.scan_op.Scan
   1.8%    97.9%     9763.392s       3.49e-05s     C   279749400       2   theano.sandbox.cuda.basic_ops.GpuAlloc
   1.0%    98.9%     5390.664s       3.85e-05s     C   139874700       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.6%    99.4%     2966.794s       1.06e-06s     C   2797494000      20   theano.tensor.elemwise.Elemwise
   0.2%    99.6%     1042.642s       9.32e-07s     C   1118997600       8   theano.tensor.basic.ScalarFromTensor
   0.2%    99.8%     806.448s       1.92e-06s     C   419624100       3   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.1%    99.9%     448.774s       6.42e-07s     C   699373500       5   theano.compile.ops.Shape_i
   0.1%    99.9%     373.820s       1.34e-06s     C   279749400       2   theano.tensor.subtensor.Subtensor
   0.0%   100.0%     179.656s       6.42e-07s     C   279749400       2   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%     150.588s       1.08e-06s     C   139874700       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  96.0%    96.0%     513244.963s       3.67e-03s     Py    139874700        1   forall_inplace,gpu,grad_of_scan_fn}
   1.8%    97.9%     9763.392s       3.49e-05s     C     279749400        2   GpuAlloc{memset_0=True}
   1.0%    98.9%     5390.664s       3.85e-05s     C     139874700        1   GpuElemwise{add,no_inplace}
   0.2%    99.1%     1042.642s       9.32e-07s     C     1118997600        8   ScalarFromTensor
   0.1%    99.2%     435.810s       1.56e-06s     C     279749400        2   GpuSubtensor{int64:int64:int64}
   0.1%    99.2%     373.820s       1.34e-06s     C     279749400        2   Subtensor{:int64:}
   0.1%    99.3%     370.638s       2.65e-06s     C     139874700        1   GpuSubtensor{int64}
   0.1%    99.4%     355.483s       8.47e-07s     C     419624100        3   Elemwise{add,no_inplace}
   0.1%    99.4%     302.916s       1.08e-06s     C     279749400        2   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 - i3), i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), (i2 - i3))))}}[(0, 2)]
   0.1%    99.5%     274.172s       6.53e-07s     C     419624100        3   Shape_i{0}
   0.0%    99.5%     259.954s       1.86e-06s     C     139874700        1   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}
   0.0%    99.6%     250.931s       8.97e-07s     C     279749400        2   Elemwise{Composite{Switch(i0, i1, maximum(i2, i3))}}
   0.0%    99.6%     221.740s       7.93e-07s     C     279749400        2   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}
   0.0%    99.7%     220.127s       1.57e-06s     C     139874700        1   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)]
   0.0%    99.7%     215.591s       1.54e-06s     C     139874700        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%    99.7%     212.266s       1.52e-06s     C     139874700        1   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)]
   0.0%    99.8%     188.410s       6.73e-07s     C     279749400        2   Elemwise{le,no_inplace}
   0.0%    99.8%     180.163s       1.29e-06s     C     139874700        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)]
   0.0%    99.8%     179.656s       6.42e-07s     C     279749400        2   GpuDimShuffle{0,1,x}
   0.0%    99.9%     167.192s       1.20e-06s     C     139874700        1   Elemwise{Composite{((i0 - i1) + i2)}}
   ... (remaining 6 Ops account for   0.13%(717.21s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  96.0%    96.0%     513244.963s       3.67e-03s   139874700    42   forall_inplace,gpu,grad_of_scan_fn}(Elemwise{maximum,no_inplace}.0, GpuDimShuffle{0,1,x}.0, GpuDimShuffle{0,1,x}.0, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, Subtensor{:int64:}.0, GpuAlloc{memset_0=True}.0, <CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, GpuAlloc{memset_0=True}.0, ScalarFromTensor.0)
   1.1%    97.1%     5663.483s       4.05e-05s   139874700    31   GpuAlloc{memset_0=True}(CudaNdarrayConstant{0.0}, Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)].0, <Tenso
   1.0%    98.1%     5390.664s       3.85e-05s   139874700    44   GpuElemwise{add,no_inplace}(GpuSubtensor{int64}.0, <CudaNdarrayType(float32, 3D)>)
   0.8%    98.9%     4099.908s       2.93e-05s   139874700    12   GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, Shape_i{0}.0, Shape_i{1}.0, Shape_i{2}.0)
   0.1%    99.0%     370.638s       2.65e-06s   139874700    43   GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.0, ScalarFromTensor.0)
   0.1%    99.0%     330.801s       2.36e-06s   139874700    28   ScalarFromTensor(Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)].0)
   0.1%    99.1%     311.702s       2.23e-06s   139874700    40   GpuSubtensor{int64:int64:int64}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})
   0.1%    99.1%     272.648s       1.95e-06s   139874700    18   Subtensor{:int64:}(<TensorType(int64, vector)>, ScalarFromTensor.0)
   0.0%    99.2%     259.954s       1.86e-06s   139874700     7   Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}(TensorConstant{1}, TensorConstant{-1}, Shape_i{0}.0)
   0.0%    99.2%     228.782s       1.64e-06s   139874700    27   Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 - i3), i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), (i2 - i3))))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{add,no_inplace}.0, Elemwise{Composite{Switch(LT(i0, (i0 - i1)), i0, (i0 - i1))}}.0, TensorConstant{-1}, Shape_i{0}.0, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0)
   0.0%    99.3%     220.127s       1.57e-06s   139874700    26   Elemwise{Composite{(Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), i3), Switch(LT((Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4), i3), i3, (Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2) + i2 + i4)), Switch(LT(Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4)), Composite{maximum(maximum(i0, i1), i2)}(i0, i1, i2), (i2 + i4))) - i3)}}[(0, 0)](Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2},
   0.0%    99.3%     215.591s       1.54e-06s   139874700    22   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{:int64:}.0, TensorConstant{(1,) of 1}, Subtensor{:int64:}.0, InplaceDimShuffle{x}.0)
   0.0%    99.3%     212.266s       1.52e-06s   139874700    24   Elemwise{Composite{(((i0 - maximum(i1, i2)) - i3) + maximum(i4, i5))}}[(0, 0)](Elemwise{add,no_inplace}.0, Elemwise{Composite{minimum(((i0 + i1 + i0 + i2) - i0), i2)}}.0, TensorConstant{1}, TensorConstant{1}, Elemwise{Composite{((i0 - i1) + i2)}}.0, TensorConstant{2})
   0.0%    99.4%     206.515s       1.48e-06s   139874700     4   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.0%    99.4%     185.703s       1.33e-06s   139874700     8   ScalarFromTensor(Shape_i{0}.0)
   0.0%    99.4%     180.163s       1.29e-06s   139874700    15   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)](<TensorType(int64, scalar)>, TensorConstant{1}, <TensorType(int64, scalar)>, Shape_i{1}.0)
   0.0%    99.5%     177.813s       1.27e-06s   139874700    25   Elemwise{Composite{Switch(i0, i1, maximum(i2, i3))}}(Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Elemwise{add,no_inplace}.0)
   0.0%    99.5%     167.192s       1.20e-06s   139874700    21   Elemwise{Composite{((i0 - i1) + i2)}}(Elemwise{maximum,no_inplace}.0, Elemwise{add,no_inplace}.0, TensorConstant{1})
   0.0%    99.5%     164.268s       1.17e-06s   139874700    10   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}(TensorConstant{0}, Shape_i{0}.0)
   0.0%    99.6%     155.143s       1.11e-06s   139874700     6   Elemwise{add,no_inplace}(TensorConstant{-1}, TensorConstant{1}, Shape_i{0}.0)
   ... (remaining 25 Apply instances account for 0.43%(2309.42s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( grad_of_scan_fn )
==================
  Message: None
  Time in 139874700 calls of the op (for a total of 979122900 steps) 4.788608e+05s

  Total time spent in calling the VM 2.821973e+05s (58.931%)
  Total overhead (computing slices..) 1.966635e+05s (41.069%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  50.5%    50.5%     135518.126s       2.77e-05s     C   4895614500       5   theano.sandbox.cuda.basic_ops.GpuElemwise
  33.8%    84.3%     90846.604s       9.28e-05s     C   979122900       1   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
  12.8%    97.1%     34330.725s       3.51e-05s     C   979122900       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
   1.1%    98.2%     2878.761s       2.94e-06s     C   979122900       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   1.0%    99.2%     2599.990s       8.85e-07s     C   2937368700       3   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.8%   100.0%     2269.577s       1.16e-06s     C   1958245800       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  33.8%    33.8%     90846.604s       9.28e-05s     C     979122900        1   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}
  17.5%    51.3%     46967.258s       2.40e-05s     C     1958245800        2   GpuElemwise{Mul}[(0, 0)]
  13.4%    64.7%     35912.536s       3.67e-05s     C     979122900        1   GpuElemwise{add,no_inplace}
  12.8%    77.5%     34330.725s       3.51e-05s     C     979122900        1   GpuCAReduce{maximum}{0,0,1}
  11.1%    88.6%     29862.911s       3.05e-05s     C     979122900        1   GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))},no_inplace}
   8.5%    97.1%     22775.422s       2.33e-05s     C     979122900        1   GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))}}[(0, 1)]
   1.1%    98.2%     2878.761s       2.94e-06s     C     979122900        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   0.8%    99.0%     2269.577s       1.16e-06s     C     1958245800        2   ScalarFromTensor
   0.6%    99.6%     1562.813s       7.98e-07s     C     1958245800        2   GpuDimShuffle{0,1,x}
   0.4%   100.0%     1037.177s       1.06e-06s     C     979122900        1   GpuDimShuffle{0,1,x}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  33.8%    33.8%     90846.604s       9.28e-05s   979122900    12   GpuIncSubtensor{Inc;::, int64:int64:, int64:int64:}(GpuElemwise{add,no_inplace}.0, GpuElemwise{Mul}[(0, 0)].0, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
  13.4%    47.2%     35912.536s       3.67e-05s   979122900     4   GpuElemwise{add,no_inplace}(<CudaNdarrayType(float32, 3D)>, <CudaNdarrayType(float32, 3D)>)
  12.8%    60.0%     34330.725s       3.51e-05s   979122900     6   GpuCAReduce{maximum}{0,0,1}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
  11.1%    71.1%     29862.911s       3.05e-05s   979122900     8   GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))},no_inplace}(GpuDimShuffle{0,1,x}.0, GpuSubtensor{::, int64:int64:, int64:int64:}.0)
   8.9%    80.0%     23763.717s       2.43e-05s   979122900    10   GpuElemwise{Mul}[(0, 0)](GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))}}[(0, 1)].0, GpuDimShuffle{0,1,x}.0)
   8.6%    88.6%     23203.541s       2.37e-05s   979122900    11   GpuElemwise{Mul}[(0, 0)](GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))},no_inplace}.0, GpuElemwise{Mul}[(0, 0)].0)
   8.5%    97.1%     22775.422s       2.33e-05s   979122900     9   GpuElemwise{Composite{Cast{float32}(EQ(i0, i1))}}[(0, 1)](GpuDimShuffle{0,1,x}.0, GpuDimShuffle{0,1,x}.0)
   1.1%    98.2%     2878.761s       2.94e-06s   979122900     5   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
   0.7%    98.9%     1911.293s       1.95e-06s   979122900     1   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.4%    99.3%     1037.177s       1.06e-06s   979122900     7   GpuDimShuffle{0,1,x}(GpuCAReduce{maximum}{0,0,1}.0)
   0.3%    99.6%     863.240s       8.82e-07s   979122900     3   GpuDimShuffle{0,1,x}(<CudaNdarrayType(float32, col)>)
   0.3%    99.9%     699.573s       7.14e-07s   979122900     2   GpuDimShuffle{0,1,x}(<CudaNdarrayType(float32, col)>)
   0.1%   100.0%     358.284s       3.66e-07s   979122900     0   ScalarFromTensor(<TensorType(int64, scalar)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: /nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:915
  Time in 35850 calls to Function.__call__: 4.551271e+04s
  Time in Function.fn.__call__: 4.550356e+04s (99.980%)
  Time in thunks: 4.505090e+04s (98.985%)
  Total compile time: 1.689329e+01s
    Number of Apply nodes: 324
    Theano Optimizer time: 1.019872e+01s
       Theano validate time: 8.639433e-01s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.462519e+00s
       Import time 2.107139e-01s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036430.192s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  84.3%    84.3%     37967.779s       3.53e-01s     Py  107550       3   theano.scan_module.scan_op.Scan
   7.9%    92.2%     3555.069s       6.20e-03s     C   573600      16   theano.sandbox.cuda.blas.GpuCorrMM
   3.0%    95.2%     1348.830s       6.27e-03s     C   215100       6   theano.sandbox.cuda.blas.GpuDot22
   1.7%    96.8%     752.019s       1.31e-03s     C   573600      16   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   1.3%    98.1%     588.348s       5.13e-04s     C   1147200      32   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.6%    98.8%     284.332s       1.93e-04s     C   1469850      41   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.4%    99.2%     173.009s       4.02e-04s     C   430200      12   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.3%    99.4%     131.024s       4.06e-04s     C   322650       9   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.2%    99.7%     102.598s       5.72e-04s     C   179250       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.1%    99.8%      64.902s       1.21e-04s     Py  537750       8   theano.ifelse.IfElse
   0.1%    99.9%      40.991s       2.86e-04s     C   143400       4   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.0%    99.9%      11.323s       5.26e-05s     C   215100       6   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.0%    99.9%       7.525s       3.13e-06s     C   2401950      67   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       5.701s       8.37e-06s     C   681150      19   theano.sandbox.cuda.basic_ops.GpuReshape
   0.0%   100.0%       5.185s       6.57e-06s     C   788700      22   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       3.077s       2.86e-05s     C   107550       3   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       2.956s       8.25e-05s     C    35850       1   theano.sandbox.cuda.nnet.GpuSoftmaxWithBias
   0.0%   100.0%       2.257s       3.31e-06s     C   681150      19   theano.compile.ops.Shape_i
   0.0%   100.0%       1.440s       1.83e-06s     C   788700      22   theano.tensor.basic.ScalarFromTensor
   0.0%   100.0%       1.212s       5.64e-06s     C   215100       6   theano.tensor.opt.MakeVector
   ... (remaining 2 Classes account for   0.00%(1.33s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  81.0%    81.0%     36485.429s       1.02e+00s     Py    35850        1   for{gpu,scan_fn}
   7.9%    88.9%     3555.069s       6.20e-03s     C     573600       16   GpuCorrMM{valid, (1, 1)}
   3.2%    92.1%     1461.602s       4.08e-02s     Py    35850        1   for{gpu,scan_fn}
   3.0%    95.1%     1348.830s       6.27e-03s     C     215100        6   GpuDot22
   1.3%    96.4%     588.348s       5.13e-04s     C     1147200       32   GpuContiguous
   1.1%    97.6%     516.376s       1.60e-03s     C     322650        9   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   0.5%    98.1%     237.076s       4.13e-04s     C     573600       16   GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)]
   0.5%    98.6%     235.643s       9.39e-04s     C     250950        7   GpuIncSubtensor{Set;::, ::, int64:int64:, int64:int64:}
   0.4%    99.0%     173.009s       4.02e-04s     C     430200       12   GpuFromHost
   0.3%    99.3%     131.024s       4.06e-04s     C     322650        9   GpuAlloc{memset_0=True}
   0.2%    99.5%     102.598s       5.72e-04s     C     179250        5   GpuDownsampleFactorMax{(2, 2),True}
   0.1%    99.6%      57.331s       2.00e-04s     Py    286800        4   if{inplace,gpu}
   0.1%    99.7%      40.991s       2.86e-04s     C     143400        4   GPU_mrg_uniform{CudaNdarrayType(float32, matrix),inplace}
   0.0%    99.8%      20.747s       5.79e-04s     Py    35850        1   for{gpu,scan_fn}
   0.0%    99.8%      15.825s       5.52e-05s     C     286800        8   GpuElemwise{Mul}[(0, 1)]
   0.0%    99.8%      11.651s       8.12e-05s     C     143400        4   GpuElemwise{Composite{((i0 + i1) + Abs((i0 + i1)))}}[(0, 0)]
   0.0%    99.9%       8.870s       6.19e-05s     C     143400        4   GpuElemwise{Composite{Cast{float32}(LT(i0, i1))}}[(0, 0)]
   0.0%    99.9%       7.043s       4.91e-05s     C     143400        4   GpuCAReduce{add}{1}
   0.0%    99.9%       5.416s       3.02e-05s     Py    179250        3   if{shape,inplace}
   0.0%    99.9%       5.023s       8.76e-06s     C     573600       16   GpuReshape{4}
   ... (remaining 34 Ops account for   0.10%(43.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  81.0%    81.0%     36485.429s       1.02e+00s   35850   217   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   3.2%    84.2%     1461.602s       4.08e-02s   35850   301   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   1.9%    86.2%     874.707s       2.44e-02s   35850   222   GpuDot22(GpuReshape{2}.0, dense_4_W)
   1.1%    87.2%     474.833s       1.32e-02s   35850   153   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.7%    87.9%     312.089s       8.71e-03s   35850   196   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.7%    88.6%     311.177s       8.68e-03s   35850   188   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.7%    89.3%     311.097s       8.68e-03s   35850   192   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.7%    90.0%     293.013s       8.17e-03s   35850   162   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.6%    90.6%     291.812s       8.14e-03s   35850   221   GpuDot22(GpuReshape{2}.0, dense_7_W)
   0.6%    91.2%     269.308s       7.51e-03s   35850   175   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.6%    91.8%     268.692s       7.49e-03s   35850   171   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.6%    92.4%     268.370s       7.49e-03s   35850   179   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.4%    92.8%     190.662s       5.32e-03s   35850   146   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}(GpuAlloc{memset_0=True}.0, GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)].0, Constant{1}, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0)
   0.4%    93.2%     173.846s       4.85e-03s   35850   184   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.4%    93.6%     168.771s       4.71e-03s   35850   158   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    93.9%     155.567s       4.34e-03s   35850   167   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    94.3%     153.504s       4.28e-03s   35850     8   GpuFromHost(batch_of_images)
   0.3%    94.6%     152.956s       4.27e-03s   35850   262   GpuDot22(if{inplace,gpu}.0, dense_5_W)
   0.3%    94.9%     129.280s       3.61e-03s   35850   160   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}(GpuAlloc{memset_0=True}.0, GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)].0, Constant{1}, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0)
   0.3%    95.1%     119.100s       3.32e-03s   35850   209   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   ... (remaining 304 Apply instances account for 4.85%(2185.09s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 35850 calls of the op (for a total of 35850 steps) 3.647671e+04s

  Total time spent in calling the VM 3.643266e+04s (99.879%)
  Total overhead (computing slices..) 4.405801e+01s (0.121%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  100.0%   100.0%     36426.304s       1.02e+00s     Py   35850       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       3.076s       8.58e-05s     C    35850       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       1.441s       1.01e-05s     C   143400       4   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.295s       2.74e-06s     C   107550       3   theano.compile.ops.Shape_i
   0.0%   100.0%       0.206s       5.74e-06s     C    35850       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.183s       5.11e-06s     C    35850       1   theano.tensor.opt.MakeVector
   0.0%   100.0%       0.114s       3.19e-06s     C    35850       1   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       0.080s       1.11e-06s     C    71700       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  100.0%   100.0%     36426.304s       1.02e+00s     Py    35850        1   for{gpu,scan_fn}
   0.0%   100.0%       3.076s       8.58e-05s     C     35850        1   HostFromGpu
   0.0%   100.0%       1.009s       2.81e-05s     C     35850        1   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}
   0.0%   100.0%       0.265s       7.39e-06s     C     35850        1   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}
   0.0%   100.0%       0.206s       5.74e-06s     C     35850        1   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.183s       5.11e-06s     C     35850        1   MakeVector{dtype='int64'}
   0.0%   100.0%       0.168s       2.34e-06s     C     71700        2   Elemwise{add,no_inplace}
   0.0%   100.0%       0.114s       3.19e-06s     C     35850        1   InplaceDimShuffle{x,0}
   0.0%   100.0%       0.105s       2.93e-06s     C     35850        1   Shape_i{2}
   0.0%   100.0%       0.105s       2.92e-06s     C     35850        1   Shape_i{0}
   0.0%   100.0%       0.086s       2.39e-06s     C     35850        1   Shape_i{1}
   0.0%   100.0%       0.080s       1.11e-06s     C     71700        2   ScalarFromTensor
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  100.0%   100.0%     36426.304s       1.02e+00s   35850    13   for{gpu,scan_fn}(Shape_i{0}.0, Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}.0, Shape_i{0}.0, <CudaNdarrayType(float32, 3D)>, Shape_i{2}.0, Shape_i{1}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0)
   0.0%   100.0%       3.076s       8.58e-05s   35850    11   HostFromGpu(GpuSubtensor{int64:int64:int8}.0)
   0.0%   100.0%       1.009s       2.81e-05s   35850    12   Elemwise{Composite{Cast{int64}(RoundHalfAwayFromZero((i0 * i1)))}}(HostFromGpu.0, InplaceDimShuffle{x,0}.0)
   0.0%   100.0%       0.265s       7.39e-06s   35850     7   Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}(Shape_i{0}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.206s       5.74e-06s   35850    10   GpuSubtensor{int64:int64:int8}(batch_of_rois[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.183s       5.11e-06s   35850     5   MakeVector{dtype='int64'}(Shape_i{2}.0, Shape_i{1}.0, Shape_i{2}.0, Shape_i{1}.0)
   0.0%   100.0%       0.137s       3.83e-06s   35850     4   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{2}.0)
   0.0%   100.0%       0.114s       3.19e-06s   35850     8   InplaceDimShuffle{x,0}(MakeVector{dtype='int64'}.0)
   0.0%   100.0%       0.105s       2.93e-06s   35850     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.105s       2.92e-06s   35850     2   Shape_i{0}(batch_of_rois[t][cuda])
   0.0%   100.0%       0.086s       2.39e-06s   35850     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%       0.047s       1.30e-06s   35850     6   ScalarFromTensor(Shape_i{0}.0)
   0.0%   100.0%       0.033s       9.31e-07s   35850     9   ScalarFromTensor(Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}}.0)
   0.0%   100.0%       0.030s       8.50e-07s   35850     3   Elemwise{add,no_inplace}(TensorConstant{-1}, Shape_i{1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 35850 calls of the op (for a total of 5546100 steps) 3.641087e+04s

  Total time spent in calling the VM 3.568141e+04s (97.997%)
  Total overhead (computing slices..) 7.294609e+02s (2.003%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  96.8%    96.8%     34421.218s       6.21e-03s     Py  5546100       1   theano.scan_module.scan_op.Scan
   1.6%    98.5%     575.890s       1.04e-04s     C   5546100       1   theano.sandbox.cuda.basic_ops.GpuReshape
   0.8%    99.3%     298.679s       1.80e-05s     Py  16638300       2   theano.ifelse.IfElse
   0.2%    99.5%      82.488s       1.06e-06s     C   77645400      14   theano.tensor.elemwise.Elemwise
   0.2%    99.7%      58.785s       5.30e-06s     C   11092200       2   theano.tensor.basic.Join
   0.1%    99.8%      37.891s       1.14e-06s     C   33276600       6   theano.tensor.subtensor.Subtensor
   0.0%    99.9%      16.569s       7.47e-07s     C   22184400       4   theano.tensor.basic.ScalarFromTensor
   0.0%    99.9%      14.815s       2.67e-06s     C   5546100       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%    99.9%      14.408s       1.30e-06s     C   11092200       2   theano.tensor.elemwise.DimShuffle
   0.0%   100.0%       8.048s       1.45e-06s     C   5546100       1   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       7.209s       6.50e-07s     C   11092200       2   theano.tensor.opt.MakeVector
   0.0%   100.0%       6.678s       6.02e-07s     C   11092200       2   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  96.8%    96.8%     34421.218s       6.21e-03s     Py    5546100        1   for{gpu,scan_fn}
   1.6%    98.5%     575.890s       1.04e-04s     C     5546100        1   GpuReshape{1}
   0.8%    99.3%     298.679s       1.80e-05s     Py    16638300        2   if{inplace}
   0.2%    99.5%      58.785s       5.30e-06s     C     11092200        2   Join
   0.1%    99.5%      25.392s       1.14e-06s     C     22184400        4   Subtensor{int64}
   0.1%    99.6%      19.258s       8.68e-07s     C     22184400        4   Elemwise{add,no_inplace}
   0.1%    99.6%      17.945s       1.62e-06s     C     11092200        2   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}
   0.0%    99.7%      16.569s       7.47e-07s     C     22184400        4   ScalarFromTensor
   0.0%    99.7%      14.815s       2.67e-06s     C     5546100        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   0.0%    99.8%      14.408s       1.30e-06s     C     11092200        2   InplaceDimShuffle{x}
   0.0%    99.8%      13.302s       1.20e-06s     C     11092200        2   Elemwise{clip,no_inplace}
   0.0%    99.8%      12.515s       1.13e-06s     C     11092200        2   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.0%    99.9%      12.499s       1.13e-06s     C     11092200        2   Subtensor{int64::}
   0.0%    99.9%      11.511s       1.04e-06s     C     11092200        2   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, 
   0.0%    99.9%       8.048s       1.45e-06s     C     5546100        1   GpuDimShuffle{2,0,1}
   0.0%   100.0%       7.958s       7.17e-07s     C     11092200        2   Elemwise{eq,no_inplace}
   0.0%   100.0%       7.209s       6.50e-07s     C     11092200        2   MakeVector{dtype='int64'}
   0.0%   100.0%       3.668s       6.61e-07s     C     5546100        1   Shape_i{1}
   0.0%   100.0%       3.010s       5.43e-07s     C     5546100        1   Shape_i{2}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  96.8%    96.8%     34421.218s       6.21e-03s   5546100    35   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Join.0, TensorConstant{7}, GpuSubtensor{::, int64:int64:, int64:int64:}.0, Join.0, Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0)
   1.6%    98.5%     575.890s       1.04e-04s   5546100    37   GpuReshape{1}(GpuDimShuffle{2,0,1}.0, TensorConstant{(1,) of -1})
   0.5%    99.0%     183.065s       3.30e-05s   5546100    17   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.3%    99.3%     115.614s       1.04e-05s   11092200    16   if{inplace}(Elemwise{eq,no_inplace}.0, Elemwise{add,no_inplace}.0, Elemwise{clip,no_inplace}.0)
   0.1%    99.4%      33.493s       6.04e-06s   5546100    34   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.1%    99.5%      25.291s       4.56e-06s   5546100    33   Join(TensorConstant{0}, Subtensor{int64::}.0, MakeVector{dtype='int64'}.0)
   0.0%    99.5%      14.815s       2.67e-06s   5546100    24   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
   0.0%    99.5%      12.860s       2.32e-06s   5546100     5   Subtensor{int64}(<TensorType(int64, vector)>, Constant{3})
   0.0%    99.6%      11.880s       2.14e-06s   5546100    30   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.6%       8.760s       1.58e-06s   5546100     7   Elemwise{clip,no_inplace}(Subtensor{int64}.0, TensorConstant{0}, <TensorType(int64, scalar)>)
   0.0%    99.6%       8.048s       1.45e-06s   5546100    36   GpuDimShuffle{2,0,1}(for{gpu,scan_fn}.0)
   0.0%    99.7%       7.752s       1.40e-06s   5546100    26   InplaceDimShuffle{x}(Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0,
   0.0%    99.7%       7.587s       1.37e-06s   5546100     9   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(Subtensor{int64}.0, TensorConstant{1}, Elemwise{clip,no_inplace}.0, <TensorType(int64, scalar)>)
   0.0%    99.7%       7.532s       1.36e-06s   5546100    32   Subtensor{int64::}(Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}.0, Constant{1})
   0.0%    99.7%       7.251s       1.31e-06s   5546100    21   Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Compos
   0.0%    99.7%       6.656s       1.20e-06s   5546100    22   InplaceDimShuffle{x}(Elemwise{Composite{(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i0, i1, i2), i1, i3), i2), i1) - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(i4, i1, i2), i1), i2), i1), Composite{Switch(LT(i0,
   0.0%    99.7%       6.065s       1.09e-06s   5546100    29   Elemwise{Composite{clip(Cast{int64}(RoundHalfAwayFromZero((i0 * i1 * i2))), i3, i4)}}(TensorConstant{(1,) of 0...2857142857}, TensorConstant{[ 0.  1.  ...  5.  6.]}, InplaceDimShuffle{x}.0, TensorConstant{(1,) of 0}, Elemwise{add,no_inplace}.0)
   0.0%    99.8%       6.043s       1.09e-06s   5546100     1   Subtensor{int64}(<TensorType(int64, vector)>, Constant{2})
   0.0%    99.8%       5.959s       1.07e-06s   5546100    28   Elemwise{add,no_inplace}(TensorConstant{(1,) of -1}, InplaceDimShuffle{x}.0)
   0.0%    99.8%       5.933s       1.07e-06s   5546100    13   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0)
   ... (remaining 18 Apply instances account for 0.20%(70.97s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 5546100 calls of the op (for a total of 38822700 steps) 3.396050e+04s

  Total time spent in calling the VM 3.270485e+04s (96.303%)
  Total overhead (computing slices..) 1.255653e+03s (3.697%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.2%    99.2%     32192.894s       8.29e-04s     Py  38822700       1   theano.scan_module.scan_op.Scan
   0.3%    99.5%      94.589s       1.22e-06s     C   77645400       2   theano.tensor.elemwise.Elemwise
   0.2%    99.7%      60.140s       7.75e-07s     C   77645400       2   theano.tensor.basic.ScalarFromTensor
   0.1%    99.9%      46.351s       5.97e-07s     C   77645400       2   theano.compile.ops.Shape_i
   0.1%   100.0%      45.694s       1.18e-06s     C   38822700       1   theano.tensor.elemwise.DimShuffle
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.2%    99.2%     32192.894s       8.29e-04s     Py    38822700        1   for{gpu,scan_fn}
   0.2%    99.4%      60.797s       1.57e-06s     C     38822700        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}
   0.2%    99.6%      60.140s       7.75e-07s     C     77645400        2   ScalarFromTensor
   0.1%    99.8%      45.694s       1.18e-06s     C     38822700        1   InplaceDimShuffle{x}
   0.1%    99.9%      33.792s       8.70e-07s     C     38822700        1   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)]
   0.1%    99.9%      25.252s       6.50e-07s     C     38822700        1   Shape_i{2}
   0.1%   100.0%      21.099s       5.43e-07s     C     38822700        1   Shape_i{1}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.2%    99.2%     32192.894s       8.29e-04s   38822700     7   for{gpu,scan_fn}(TensorConstant{7}, Elemwise{Composite{clip(i0, (i1 + i2), i3)}}.0, <TensorType(int64, vector)>, TensorConstant{7}, <CudaNdarrayType(float32, 3D)>, ScalarFromTensor.0, ScalarFromTensor.0)
   0.2%    99.4%      60.797s       1.57e-06s   38822700     6   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}(<TensorType(int64, vector)>, TensorConstant{(1,) of 1}, <TensorType(int64, vector)>, InplaceDimShuffle{x}.0)
   0.1%    99.6%      47.396s       1.22e-06s   38822700     2   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.1%    99.7%      45.694s       1.18e-06s   38822700     4   InplaceDimShuffle{x}(Shape_i{2}.0)
   0.1%    99.8%      33.792s       8.70e-07s   38822700     3   Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)](<TensorType(int64, scalar)>, TensorConstant{1}, <TensorType(int64, scalar)>, Shape_i{1}.0)
   0.1%    99.9%      25.252s       6.50e-07s   38822700     1   Shape_i{2}(<CudaNdarrayType(float32, 3D)>)
   0.1%   100.0%      21.099s       5.43e-07s   38822700     0   Shape_i{1}(<CudaNdarrayType(float32, 3D)>)
   0.0%   100.0%      12.743s       3.28e-07s   38822700     5   ScalarFromTensor(Elemwise{Composite{clip(i0, (i1 + i2), i3)}}[(0, 3)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 38822700 calls of the op (for a total of 271758900 steps) 2.810842e+04s

  Total time spent in calling the VM 1.999169e+04s (71.123%)
  Total overhead (computing slices..) 8.116729e+03s (28.877%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  95.3%    95.3%     17650.628s       3.25e-05s     C   543517800       2   theano.sandbox.cuda.basic_ops.GpuCAReduce
   2.6%    97.9%     489.798s       1.80e-06s     C   271758900       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   2.1%   100.0%     379.690s       6.99e-07s     C   543517800       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  52.8%    52.8%     9777.385s       3.60e-05s     C     271758900        1   GpuCAReduce{maximum}{0,0,1}
  42.5%    95.3%     7873.243s       2.90e-05s     C     271758900        1   GpuCAReduce{maximum}{0,1}
   2.6%    97.9%     489.798s       1.80e-06s     C     271758900        1   GpuSubtensor{::, int64:int64:, int64:int64:}
   2.1%   100.0%     379.690s       6.99e-07s     C     543517800        2   ScalarFromTensor
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  52.8%    52.8%     9777.385s       3.60e-05s   271758900     3   GpuCAReduce{maximum}{0,0,1}(GpuSubtensor{::, int64:int64:, int64:int64:}.0)
  42.5%    95.3%     7873.243s       2.90e-05s   271758900     4   GpuCAReduce{maximum}{0,1}(GpuCAReduce{maximum}{0,0,1}.0)
   2.6%    97.9%     489.798s       1.80e-06s   271758900     2   GpuSubtensor{::, int64:int64:, int64:int64:}(<CudaNdarrayType(float32, 3D)>, <int64>, <int64>, ScalarFromTensor.0, ScalarFromTensor.0)
   1.6%    99.6%     303.225s       1.12e-06s   271758900     1   ScalarFromTensor(<TensorType(int64, scalar)>)
   0.4%   100.0%      76.465s       2.81e-07s   271758900     0   ScalarFromTensor(<TensorType(int64, scalar)>)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 35850 calls of the op (for a total of 35850 steps) 1.454269e+03s

  Total time spent in calling the VM 1.445402e+03s (99.390%)
  Total overhead (computing slices..) 8.867176e+00s (0.610%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  99.9%    99.9%     1443.130s       4.03e-02s     Py   35850       1   theano.scan_module.scan_op.Scan
   0.0%   100.0%       0.643s       1.79e-06s     C   358500      10   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.253s       3.53e-06s     C    71700       2   theano.compile.ops.Shape_i
   0.0%   100.0%       0.224s       3.13e-06s     C    71700       2   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%       0.138s       9.64e-07s     C   143400       4   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  99.9%    99.9%     1443.130s       4.03e-02s     Py    35850        1   for{gpu,scan_fn}
   0.0%    99.9%       0.253s       3.53e-06s     C     71700        2   Shape_i{0}
   0.0%    99.9%       0.224s       3.13e-06s     C     71700        2   GpuSubtensor{int64:int64:int8}
   0.0%   100.0%       0.179s       2.50e-06s     C     71700        2   Elemwise{switch,no_inplace}
   0.0%   100.0%       0.158s       4.41e-06s     C     35850        1   Elemwise{lt,no_inplace}
   0.0%   100.0%       0.138s       9.64e-07s     C     143400        4   ScalarFromTensor
   0.0%   100.0%       0.108s       1.50e-06s     C     71700        2   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}
   0.0%   100.0%       0.086s       1.20e-06s     C     71700        2   Elemwise{le,no_inplace}
   0.0%   100.0%       0.060s       8.43e-07s     C     71700        2   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   0.0%   100.0%       0.052s       1.46e-06s     C     35850        1   Elemwise{minimum,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  99.9%    99.9%     1443.130s       4.03e-02s   35850    18   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.0%    99.9%       0.179s       4.98e-06s   35850     1   Shape_i{0}(bbox_output_target[t][cuda])
   0.0%    99.9%       0.158s       4.41e-06s   35850     3   Elemwise{lt,no_inplace}(Elemwise{minimum,no_inplace}.0, TensorConstant{0})
   0.0%    99.9%       0.158s       4.40e-06s   35850    17   GpuSubtensor{int64:int64:int8}(bbox_output_target[t][cuda], ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.142s       3.96e-06s   35850    11   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.074s       2.07e-06s   35850     0   Shape_i{0}(<CudaNdarrayType(float32, matrix)>)
   0.0%   100.0%       0.067s       1.85e-06s   35850    16   GpuSubtensor{int64:int64:int8}(<CudaNdarrayType(float32, matrix)>, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.0%   100.0%       0.058s       1.62e-06s   35850    15   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.058s       1.62e-06s   35850     5   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.053s       1.48e-06s   35850     6   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.052s       1.46e-06s   35850     2   Elemwise{minimum,no_inplace}(Shape_i{0}.0, Shape_i{0}.0)
   0.0%   100.0%       0.050s       1.38e-06s   35850     4   Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}(Elemwise{lt,no_inplace}.0, Elemwise{minimum,no_inplace}.0, Shape_i{0}.0, TensorConstant{0})
   0.0%   100.0%       0.039s       1.10e-06s   35850    14   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   0.0%   100.0%       0.039s       1.09e-06s   35850    10   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.037s       1.04e-06s   35850     9   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.0%   100.0%       0.033s       9.24e-07s   35850     7   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, TensorConstant{0})
   0.0%   100.0%       0.026s       7.13e-07s   35850    13   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.0%   100.0%       0.021s       5.91e-07s   35850     8   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i1, i2), i1, i2))}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.015s       4.25e-07s   35850    12   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 35850 calls of the op (for a total of 5546100 steps) 1.427420e+03s

  Total time spent in calling the VM 1.196048e+03s (83.791%)
  Total overhead (computing slices..) 2.313720e+02s (16.209%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  43.0%    43.0%     475.377s       1.80e-05s     Py  26451050       5   theano.ifelse.IfElse
  27.4%    70.4%     302.469s       2.84e-05s     C   10633050      13   theano.sandbox.cuda.basic_ops.GpuElemwise
  26.5%    96.8%     292.583s       2.85e-05s     C   10271900       5   theano.sandbox.cuda.basic_ops.HostFromGpu
   1.9%    98.7%      21.188s       1.41e-06s     C   14997700       9   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.9%    99.7%      10.076s       9.81e-07s     C   10271900       5   theano.tensor.elemwise.Elemwise
   0.3%   100.0%       3.826s       6.90e-07s     C   5546100       1   theano.compile.ops.ViewOp
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  43.0%    43.0%     475.377s       1.80e-05s     Py    26451050        5   if{inplace,gpu}
  26.5%    69.5%     292.583s       2.85e-05s     C     10271900        5   HostFromGpu
  12.2%    81.7%     135.200s       2.86e-05s     C     4725800        4   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}
  12.2%    93.9%     134.585s       2.85e-05s     C     4725800        4   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}
   3.0%    96.8%      32.684s       2.77e-05s     C     1181450        1   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)]
   1.9%    98.7%      21.188s       1.41e-06s     C     14997700        9   GpuSubtensor{int64}
   0.5%    99.2%       5.508s       9.93e-07s     C     5546100        1   Elemwise{eq,no_inplace}
   0.4%    99.7%       4.568s       9.67e-07s     C     4725800        4   Elemwise{lt,no_inplace}
   0.3%   100.0%       3.826s       6.90e-07s     C     5546100        1   ViewOp
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  26.1%    26.1%     289.074s       2.36e-05s   12273650    36   if{inplace,gpu}(Elemwise{eq,no_inplace}.0, CudaNdarrayConstant{0.0}, GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)].0)
  14.9%    41.1%     165.149s       2.98e-05s   5546100     9   HostFromGpu(GpuSubtensor{int64}.0)
   4.2%    45.3%      46.843s       1.32e-05s   3544350    34   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   4.2%    49.6%      46.791s       1.32e-05s   3544350    31   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   4.2%    53.8%      46.465s       1.31e-05s   3544350    33   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   4.2%    57.9%      46.203s       1.30e-05s   3544350    32   if{inplace,gpu}(Elemwise{lt,no_inplace}.0, GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}.0, GpuElemwise{Add}[(0, 1)].0)
   3.2%    61.1%      35.049s       2.97e-05s   1181450    10   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   3.1%    64.2%      33.990s       2.88e-05s   1181450    15   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   3.1%    67.2%      33.800s       2.86e-05s   1181450    21   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   3.1%    70.3%      33.749s       2.86e-05s   1181450    17   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   3.0%    73.3%      33.661s       2.85e-05s   1181450    19   GpuElemwise{Composite{((i0 * i1) * i1)},no_inplace}(CudaNdarrayConstant{0.5}, GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   3.0%    76.4%      33.404s       2.83e-05s   1181450    13   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   3.0%    79.4%      33.150s       2.81e-05s   1181450    11   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   3.0%    82.3%      32.982s       2.79e-05s   1181450    12   GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}(GpuSubtensor{int64}.0, GpuSubtensor{int64}.0)
   3.0%    85.3%      32.684s       2.77e-05s   1181450    35   GpuElemwise{Composite{(((i0 + i1) + i2) + i3)}}[(0, 0)](if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0, if{inplace,gpu}.0)
   2.9%    88.2%      31.953s       2.70e-05s   1181450    22   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.9%    91.1%      31.951s       2.70e-05s   1181450    16   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.9%    94.0%      31.769s       2.69e-05s   1181450    20   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   2.9%    96.8%      31.761s       2.69e-05s   1181450    18   HostFromGpu(GpuElemwise{Composite{Abs((i0 - i1))},no_inplace}.0)
   0.9%    97.8%      10.437s       1.88e-06s   5546100     1   GpuSubtensor{int64}(bbox_output_target[t][t][cuda], Constant{0})
   ... (remaining 18 Apply instances account for 2.23%(24.65s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

Scan Op profiling ( scan_fn )
==================
  Message: None
  Time in 35850 calls of the op (for a total of 35850 steps) 1.459554e+01s

  Total time spent in calling the VM 5.597677e+00s (38.352%)
  Total overhead (computing slices..) 8.997863e+00s (61.648%)

Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  53.8%    53.8%       2.754s       7.68e-05s     C    35850       1   theano.sandbox.cuda.basic_ops.GpuCAReduce
  46.2%   100.0%       2.365s       6.60e-05s     C    35850       1   theano.sandbox.cuda.basic_ops.GpuElemwise
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  53.8%    53.8%       2.754s       7.68e-05s     C     35850        1   GpuCAReduce{add}{0,1}
  46.2%   100.0%       2.365s       6.60e-05s     C     35850        1   GpuElemwise{neg,no_inplace}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  53.8%    53.8%       2.754s       7.68e-05s   35850     0   GpuCAReduce{add}{0,1}(<CudaNdarrayType(float32, matrix)>)
  46.2%   100.0%       2.365s       6.60e-05s   35850     1   GpuElemwise{neg,no_inplace}(GpuCAReduce{add}{0,1}.0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: Sum of all(122) printed profiles at exit excluding Scan op profile.
  Time in 185986 calls to Function.__call__: 1.034489e+06s
  Time in Function.fn.__call__: 1.034313e+06s (99.983%)
  Time in thunks: 1.027735e+06s (99.347%)
  Total compile time: 1.146653e+02s
    Number of Apply nodes: 1
    Theano Optimizer time: 5.298563e+01s
       Theano validate time: 2.230813e+00s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.836599e+01s
       Import time 3.144660e+00s

Time in all call to theano.grad() 1.543476e+00s
Time since theano import 1036430.316s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  90.5%    90.5%     930196.244s       1.08e+00s     Py  857550       8   theano.scan_module.scan_op.Scan
   2.2%    92.7%     22583.671s       9.41e-03s     C   2400000      16   theano.sandbox.cuda.blas.GpuCorrMM_gradWeights
   1.8%    94.6%     18970.583s       6.38e-03s     C   2973600      32   theano.sandbox.cuda.blas.GpuCorrMM
   1.5%    96.1%     15444.170s       6.86e-03s     C   2250000      15   theano.sandbox.cuda.blas.GpuCorrMM_gradInputs
   1.1%    97.2%     11676.735s       5.79e-03s     C   2015100      18   theano.sandbox.cuda.blas.GpuDot22
   1.0%    98.1%     9821.639s       3.66e-04s     C   26819850     213   theano.sandbox.cuda.basic_ops.GpuElemwise
   0.6%    98.7%     6090.979s       7.30e-04s     C   8347200      80   theano.sandbox.cuda.basic_ops.GpuContiguous
   0.4%    99.1%     4078.330s       1.05e-03s     C   3873600      38   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   0.3%    99.5%     3426.108s       3.81e-03s     C   900000       6   theano.sandbox.cuda.blas.GpuGemm
   0.1%    99.6%     1149.232s       3.62e-04s     C   3172650      28   theano.sandbox.cuda.basic_ops.GpuAlloc
   0.1%    99.7%     1031.254s       4.08e-04s     C   2530200      26   theano.sandbox.cuda.basic_ops.GpuFromHost
   0.1%    99.8%     910.538s       1.21e-03s     C   750000       5   theano.sandbox.cuda.blas.GpuDownsampleFactorMaxGrad
   0.1%    99.8%     707.767s       1.66e-04s     C   4265100      33   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.1%    99.9%     552.514s       5.95e-04s     C   929250      10   theano.sandbox.cuda.blas.GpuDownsampleFactorMax
   0.0%    99.9%     272.070s       3.66e-04s     C   743400       8   theano.sandbox.rng_mrg.GPU_mrg_uniform
   0.0%    99.9%     256.337s       4.32e-05s     Py  5937750      26   theano.ifelse.IfElse
   0.0%   100.0%     170.878s       4.59e-06s     C   37201950     299   theano.tensor.elemwise.Elemwise
   0.0%   100.0%      98.127s       8.81e-06s     C   11138700      91   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.0%   100.0%      61.801s       5.34e-05s     C   1157550      10   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%      53.178s       8.14e-06s     C   6531150      58   theano.sandbox.cuda.basic_ops.GpuReshape
   ... (remaining 10 Classes account for   0.02%(183.33s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  68.9%    68.9%     708482.379s       4.72e+00s     Py    150000        1   for{gpu,grad_of_scan_fn}
  17.6%    86.6%     181128.261s       9.75e-01s     Py    185850        2   for{gpu,scan_fn}
   3.2%    89.8%     33245.893s       2.22e-01s     Py    150000        1   for{gpu,grad_of_scan_fn}
   2.2%    92.0%     22583.671s       9.41e-03s     C     2400000       16   GpuCorrMM_gradWeights{valid, (1, 1)}
   1.8%    93.8%     18970.583s       6.38e-03s     C     2973600       32   GpuCorrMM{valid, (1, 1)}
   1.5%    95.3%     15444.170s       6.86e-03s     C     2250000       15   GpuCorrMM_gradInputs{valid, (1, 1)}
   1.1%    96.5%     11676.735s       5.79e-03s     C     2015100       18   GpuDot22
   0.7%    97.2%     7200.364s       3.87e-02s     Py    185850        2   for{gpu,scan_fn}
   0.6%    97.8%     6090.979s       7.30e-04s     C     8347200       80   GpuContiguous
   0.3%    98.1%     3426.108s       3.81e-03s     C     900000        6   GpuGemm{inplace}
   0.3%    98.4%     2687.134s       1.61e-03s     C     1672650       18   GpuIncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}
   0.3%    98.6%     2648.170s       3.64e-04s     C     7271700       50   GpuElemwise{Add}[(0, 0)]
   0.2%    98.8%     1946.447s       6.49e-04s     C     3000000       20   GpuElemwise{add,no_inplace}
   0.2%    99.0%     1632.312s       6.80e-04s     C     2400000       16   GpuElemwise{Composite{((i0 * i1) + (i0 * i1 * sgn(i2)))}}[(0, 1)]
   0.2%    99.1%     1625.941s       6.77e-04s     C     2400000       16   GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}
   0.1%    99.3%     1311.690s       1.01e-03s     C     1300950       14   GpuIncSubtensor{Set;::, ::, int64:int64:, int64:int64:}
   0.1%    99.4%     1098.370s       3.82e-04s     C     2872650       26   GpuAlloc{memset_0=True}
   0.1%    99.5%     1031.254s       4.08e-04s     C     2530200       26   GpuFromHost
   0.1%    99.6%     910.538s       1.21e-03s     C     750000        5   GpuDownsampleFactorMaxGrad{(2, 2),True}
   0.1%    99.6%     827.744s       1.49e-04s     C     5550000       37   GpuElemwise{Composite{((i0 * i1) - (i2 * i3))}}[(0, 1)]
   ... (remaining 105 Ops account for   0.37%(3766.74s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  68.9%    68.9%     708482.379s       4.72e+00s   150000   697   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{Add}[(0, 0)].0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
  14.1%    83.0%     144642.832s       9.64e-01s   150000   355   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   3.6%    86.6%     36485.429s       1.02e+00s   35850   217   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   3.2%    89.8%     33245.893s       2.22e-01s   150000   626   for{gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc.0, GpuSubtensor{int64:int64:int64}.0, Elemwise{minimum,no_inplace}.0)
   0.6%    90.4%     5738.761s       3.83e-02s   150000   552   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.4%    90.8%     4507.065s       3.00e-02s   150000   892   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.4%    91.2%     3687.262s       2.46e-02s   150000   904   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.3%    91.5%     3389.767s       2.26e-02s   150000   688   GpuDot22(GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))}}[(0, 2)].0, GpuDimShuffle{1,0}.0)
   0.3%    91.8%     3305.832s       2.20e-02s   150000   361   GpuDot22(GpuReshape{2}.0, dense_4_W)
   0.3%    92.1%     2589.036s       1.73e-02s   150000   891   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.3%     2335.302s       1.56e-02s   150000   690   GpuGemm{inplace}(<CudaNdarrayType(float32, matrix)>, HostFromGpu.0, GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4)) + (i0 * Composite{((i0 * i1 * i2) + i3)}(i1, i2, i3, i4) * sgn(i5)))}}[(0, 2)].0, HostFromGpu.0)
   0.2%    92.5%     2014.765s       1.34e-02s   150000   246   GpuCorrMM{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.7%     1976.026s       1.32e-02s   150000   864   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    92.8%     1720.113s       1.15e-02s   150000   865   GpuCorrMM_gradInputs{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    93.0%     1593.626s       1.06e-02s   150000   825   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    93.1%     1593.259s       1.06e-02s   150000   812   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.2%    93.3%     1590.106s       1.06e-02s   150000   838   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   0.1%    93.4%     1461.602s       4.08e-02s   35850   301   for{gpu,scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int8}.0, GpuSubtensor{int64:int64:int8}.0, Elemwise{minimum,no_inplace}.0)
   0.1%    93.6%     1405.646s       9.37e-03s   150000   693   GpuElemwise{Add}[(0, 0)](dense_4_W, GpuGemm{inplace}.0)
   0.1%    93.7%     1386.329s       9.24e-03s   150000   878   GpuCorrMM_gradWeights{valid, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
   ... (remaining 1532 Apply instances account for 6.28%(64584.45s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.

real	17274m38.132s
user	15122m49.367s
sys	1991m34.860s
